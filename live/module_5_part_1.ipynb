{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Array\n",
    "Input=[\n",
    "    [1,0,1],\n",
    "    [1,1,1],\n",
    "    [0,0,1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Array\n",
    "Output=[\n",
    "    [1],\n",
    "    [1],\n",
    "    [0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(Input)\n",
    "y = np.array(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), (3, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![../notebooks/images/title](../notebooks/images/graph.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons at input hidden and output layer\n",
    "# Weights initialization for edges between input and hidden layer\n",
    "# bias for hidden layer neurons\n",
    "# Weights initialization for edges between hidden and output layer\n",
    "# bias for output layer neuron(s)\n",
    "# Define activation function for hidden layer and output layer neurons\n",
    "# Define derivative of activation function for hidden and output layer neurons\n",
    "# Forward Propagation\n",
    "# Backward Propagation\n",
    "# Train for more number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputlayer_neurons = 3\n",
    "hiddenlayer_neurons = 2\n",
    "outputlayer_neuron = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wih = np.round(np.random.uniform(size=(inputlayer_neurons, hiddenlayer_neurons)), decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 1. ],\n",
       "       [0.7, 0.6],\n",
       "       [0.2, 0.2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bih = np.round(np.random.uniform(size=(1, hiddenlayer_neurons)), decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "who = np.round(np.random.uniform(size=(hiddenlayer_neurons, outputlayer_neuron)), decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bho = np.round(np.random.uniform(size=(1, outputlayer_neuron)), decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6],\n",
       "       [0.7]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../notebooks/images/sigmoid-equation.png\" alt=\"drawing\" style=\"width:150px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_sigmoid(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply input with weight matrix (input and hidden layer) and add bias matrix\n",
    "# apply activation function on weighted input to generate hidden layer activations\n",
    "# multiply hidden layer activations with weight matrix (hidden and output) and add bias matrix\n",
    "# Apply activatoin function on weighted hidden layer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3), (3, 2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, wih.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_input = np.dot(X, wih) + bih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 1. ],\n",
       "       [0.7, 0.6],\n",
       "       [0.2, 0.2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6, 1.2],\n",
       "       [1.3, 1.8],\n",
       "       [0.2, 0.2]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X, wih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000000000000001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*0.4 + 0*0.7 + 1*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.9]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2), (3, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bih.shape, np.dot(X, wih).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7, 2.1],\n",
       "       [1.4, 2.7],\n",
       "       [0.3, 1.1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6681877721681662"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8909031788043871"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66818777, 0.89090318],\n",
       "       [0.80218389, 0.93702664],\n",
       "       [0.57444252, 0.75026011]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddenlayer_activations = sigmoid(weighted_input)\n",
    "hiddenlayer_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_hidden_layer_activation = np.dot(hiddenlayer_activations, who) + bho\n",
    "output = sigmoid(weighted_hidden_layer_activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73585694],\n",
       "       [0.75717051],\n",
       "       [0.70471398]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../notebooks/images/all_matrices.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../notebooks/images/graph.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03488578],\n",
       "       [0.02948308],\n",
       "       [0.2483109 ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backpropagation\n",
    "\n",
    "# step 1 - calculate error\n",
    "error = ((y - output)*(y - output)) / 2\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 - calculate change in error with respect to who\n",
    "    # step 2.1 - find change in error with respect to output\n",
    "    \n",
    "change_error_wrt_output = y - output\n",
    "    \n",
    "    # step 2.2 - find change in output with respect to weighted hidden layer activations\n",
    "    \n",
    "change_output_wrt_weighted_hidden_layer_activations = derivative_sigmoid(output)\n",
    "    \n",
    "    # step 2.3 - find change in weighted hidden layer activations with respect to who\n",
    "    \n",
    "change_weighted_hidden_layer_activations_wrt_who = hiddenlayer_activations\n",
    "    \n",
    "    # step 2.4 - calculate change in error with respect to who\n",
    "delta_who = np.dot(\n",
    "    change_weighted_hidden_layer_activations_wrt_who.T,\n",
    "    (change_error_wrt_output * change_output_wrt_weighted_hidden_layer_activations)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - calculate change in error with respect to bho\n",
    "    # step 3.1 - find change in error with respect to output\n",
    "    # step 3.2 - find change in output with respect to weighted hidden layer activations\n",
    "    # step 3.3 - find change in weighted hidden layer activations with respect to bho\n",
    "    \n",
    "change_weighted_hidden_layer_activations_wrt_bho = np.ones((3, 1))\n",
    "    \n",
    "    # step 3.4 - calculate change in error with respect to bho\n",
    "delta_bho = np.dot(\n",
    "    change_weighted_hidden_layer_activations_wrt_bho.T,\n",
    "    (change_error_wrt_output * change_output_wrt_weighted_hidden_layer_activations)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1), (1, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_bho.shape, bho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - calculate change in error with respect to wih\n",
    "    # step 4.1 - find change in error with respect to output\n",
    "change_error_wrt_output\n",
    "    # step 4.2 - find change in output with respect to weighted hidden layer activations\n",
    "change_output_wrt_weighted_hidden_layer_activations\n",
    "    # step 4.3 - find change in weighted hidden layer activations with respect to hidden layer activations\n",
    "change_weighted_hidden_layer_activations_wrt_hidden_layer_activations = who\n",
    "    # step 4.4 - find change in hidden layer activations with respect to weighted input\n",
    "change_hidden_layer_activations_wrt_weighted_input = derivative_sigmoid(hiddenlayer_activations)\n",
    "    # step 4.5 - find change in weighted input with respect to wih\n",
    "change_weighted_input_wrt_wih = X\n",
    "    # step 4.6 - calculate change in error with respect to wih\n",
    "delta_wih = np.dot(\n",
    "    change_weighted_input_wrt_wih.T,\n",
    "    change_hidden_layer_activations_wrt_weighted_input * \n",
    "    np.dot(\n",
    "        (change_error_wrt_output * change_output_wrt_weighted_hidden_layer_activations),\n",
    "        change_weighted_hidden_layer_activations_wrt_hidden_layer_activations.T\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 - calculate change in error with respect to bih\n",
    "    # step 5.1 - find change in error with respect to output\n",
    "    # step 5.2 - find change in output with respect to weighted hidden layer activations\n",
    "    # step 5.3 - find change in weighted hidden layer activations with respect to hidden layer activations\n",
    "    # step 5.4 - find change in hidden layer activations with respect to weighted input\n",
    "    # step 5.5 - find change in weighted input with respect to bih\n",
    "    \n",
    "change_weighted_input_wrt_bih = np.ones((3, 1))\n",
    "    \n",
    "    # step 5.6 - calculate error with respect to bih\n",
    "delta_bih = np.dot(\n",
    "    change_weighted_input_wrt_bih.T,\n",
    "    change_hidden_layer_activations_wrt_weighted_input * \n",
    "    np.dot(\n",
    "        (change_error_wrt_output * change_output_wrt_weighted_hidden_layer_activations),\n",
    "        change_weighted_hidden_layer_activations_wrt_hidden_layer_activations.T\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01411792],\n",
       "       [-0.02244576]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05065615]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_bho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01108082,  0.00533729],\n",
       "       [ 0.00425092,  0.00184418],\n",
       "       [-0.0104284 , -0.01389657]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_wih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0104284 , -0.01389657]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_bih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6 - update who, wih, bho, bih\n",
    "who += delta_who * 0.1\n",
    "wih += delta_wih * 0.1\n",
    "bih += delta_bih * 0.1\n",
    "bho += delta_bho * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73424229],\n",
       "       [0.75561556],\n",
       "       [0.70299861]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward prop\n",
    "\n",
    "#1) Multiply hidden layer activation with weight matrix (Input and Hidden Layer)\n",
    "weighted_input=np.dot(X,wih) + bih\n",
    "\n",
    "#2) Apply activation function on weighted_input\n",
    "hiddenlayer_activations = sigmoid(weighted_input)\n",
    "\n",
    "#3) Multiply hidden layer activation with weight matrix (Hidden Layer and Output)\n",
    "weighted_hidden_layer_activation=np.dot(hiddenlayer_activations,who) + bho\n",
    "\n",
    "#4) Apply activation function on weighted_hidden_layer_activation\n",
    "new_output = sigmoid(weighted_hidden_layer_activation)\n",
    "new_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73585694],\n",
       "       [0.75717051],\n",
       "       [0.70471398]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72391394],\n",
       "       [0.74569277],\n",
       "       [0.69195775]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Backpropagation\n",
    "\n",
    "# step 1 - calculate error\n",
    "error = ((y-output)*(y-output))/2\n",
    "\n",
    "# step 2 - find change in error with respect to who\n",
    "    # step 2.1 - change in error with respect to output\n",
    "    \n",
    "change_error_output = y-output\n",
    "\n",
    "    # step 2.2 - change in output wrt weighted_hidden_layer_activation\n",
    "    \n",
    "change_output_wrt_weighted_hidden_layer_activation = derivative_sigmoid(output)\n",
    "\n",
    "\n",
    "    # step 2.3 - change in weighted_hidden_layer_activation wrt who\n",
    "    \n",
    "change_weighted_hidden_layer_activation_wrt_who = hiddenlayer_activations\n",
    "\n",
    "\n",
    "    # step 2.4 - calculate change in error with respect to who\n",
    "    \n",
    "delta_who = np.dot(change_weighted_hidden_layer_activation_wrt_who.T, change_error_output * change_output_wrt_weighted_hidden_layer_activation)\n",
    "\n",
    "# step 3 - find change in error with respect to bho\n",
    "    # step 3.1 - change in error with respect to output \n",
    "    \n",
    "# (already calculated in step 1.1)\n",
    "\n",
    "    # step 3.2 - change in output wrt weighted_hidden_layer_activation \n",
    "    \n",
    "# (already calculated in step 1.2)\n",
    "\n",
    "\n",
    "    \n",
    "    # step 3.3 - change in weighted_hidden_layer_activation wrt bho\n",
    "    \n",
    "change_weighted_hidden_layer_activation_wrt_bho = np.array([[1], [1], [1]])\n",
    "\n",
    "\n",
    "\n",
    "    # step 3.4 - calculate change in error with respect to who\n",
    "\n",
    "delta_bho = np.dot(change_weighted_hidden_layer_activation_wrt_bho.T, change_error_output * change_output_wrt_weighted_hidden_layer_activation)\n",
    "\n",
    "\n",
    "    \n",
    "# step 4 - change in error wrt wih\n",
    "    # step 4.1 - change in error with respect to output \n",
    "        \n",
    "# (already calculated in step 1.1)\n",
    "\n",
    "    # step 4.2 - change in output wrt weighted_hidden_layer_activation \n",
    "        \n",
    "# (already calculated in step 1.2)\n",
    "\n",
    "\n",
    "        \n",
    "    # step 4.3 - change in weighted_hidden_layer_activation wrt hidden_layer_activation\n",
    "        \n",
    "change_weighted_hidden_layer_activation_wrt_hidden_layer_activation = who\n",
    "\n",
    "\n",
    "    # step 4.4 - change in hidden_layer_activation wrt weighted_input\n",
    "    \n",
    "change_hidden_layer_activation_wrt_weighted_input = derivative_sigmoid(hiddenlayer_activations)\n",
    "    \n",
    "\n",
    "    # step 4.5 - change in weighted_input wrt wih\n",
    "    \n",
    "change_weighted_input_wrt_wih = X\n",
    "\n",
    "\n",
    "    # step 4.6 - calculate error wrt wih\n",
    "    \n",
    "delta_wih = np.dot(change_weighted_input_wrt_wih.T, (change_hidden_layer_activation_wrt_weighted_input * (change_error_output * change_output_wrt_weighted_hidden_layer_activation).dot(change_weighted_hidden_layer_activation_wrt_hidden_layer_activation.T)))\n",
    "\n",
    "# step 5 - change in error wrt bih\n",
    "    # step 5.1 - change in error with respect to output \n",
    "\n",
    "# (already calculated in step 1.1)\n",
    "\n",
    "        \n",
    "        \n",
    "    # step 5.2 - change in output wrt weighted_hidden_layer_activation \n",
    "    \n",
    "# (already calculated in step 1.2)\n",
    "\n",
    "    # step 5.3 - change in weighted_hidden_layer_activation wrt hidden_layer_activation \n",
    "        \n",
    "# (already calculated in step 4.1.3)\n",
    "\n",
    "    # step 5.4 - change in hidden_layer_activation wrt weighted_input\n",
    "    \n",
    "# (already calculated in step 4.2)\n",
    "    \n",
    "    # step 5.5 - change in weighted_input wrt bih\n",
    "    \n",
    "change_weighted_input_wrt_bih = np.array([[1.], [1.], [1.]])\n",
    "\n",
    "    # step 5.6 - calculate error wrt bih\n",
    "    \n",
    "delta_bih = np.dot(change_weighted_input_wrt_bih.T, (change_hidden_layer_activation_wrt_weighted_input * (change_error_output * change_output_wrt_weighted_hidden_layer_activation).dot(change_weighted_hidden_layer_activation_wrt_hidden_layer_activation.T)))\n",
    "\n",
    "# step 6 - update who, wih, bho, bih\n",
    "    # step 6.1 - who is updated with a part of change in error wrt who\n",
    "who += delta_who * 0.1\n",
    "\n",
    "    # step 6.2 - wih is updated with a part of change in error wrt wih\n",
    "wih += delta_wih * 0.1\n",
    "\n",
    "    # step 6.3 - bho is updated with a part of change in error wrt bho\n",
    "bho += delta_bho * 0.1\n",
    "\n",
    "    # step 6.4 - bih is updated with a part of change in error wrt bih\n",
    "bih += delta_bih * 0.1\n",
    "\n",
    "# Forward Prop\n",
    "#1) Multiply hidden layer activation with weight matrix (Input and Hidden Layer)\n",
    "weighted_input=np.dot(X,wih) + bih\n",
    "\n",
    "#2) Apply activation function on weighted_input\n",
    "hiddenlayer_activations = sigmoid(weighted_input)\n",
    "\n",
    "#3) Multiply hidden layer activation with weight matrix (Hidden Layer and Output)\n",
    "weighted_hidden_layer_activation=np.dot(hiddenlayer_activations,who) + bho\n",
    "\n",
    "#4) Apply activation function on weighted_hidden_layer_activation\n",
    "output = sigmoid(weighted_hidden_layer_activation)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95859347]\n",
      " [0.98253517]\n",
      " [0.05873176]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5000):\n",
    "    # Forward Propagation\n",
    "\n",
    "    #1) Multiply hidden layer activation with weight matrix (Input and Hidden Layer)\n",
    "    weighted_input=np.dot(X,wih) + bih\n",
    "\n",
    "    #2) Apply activation function on weighted_input\n",
    "    hiddenlayer_activations = sigmoid(weighted_input)\n",
    "\n",
    "    #3) Multiply hidden layer activation with weight matrix (Hidden Layer and Output)\n",
    "    weighted_hidden_layer_activation=np.dot(hiddenlayer_activations,who) + bho\n",
    "\n",
    "    #4) Apply activation function on weighted_hidden_layer_activation\n",
    "    output = sigmoid(weighted_hidden_layer_activation)\n",
    "\n",
    "    #Backpropagation\n",
    "\n",
    "    # step 1 - calculate error\n",
    "    error = ((y-output)*(y-output))/2\n",
    "\n",
    "    # step 2 - find change in error with respect to who\n",
    "        # step 2.1 - change in error with respect to output\n",
    "\n",
    "    change_error_output = y-output\n",
    "\n",
    "        # step 2.2 - change in output wrt weighted_hidden_layer_activation\n",
    "\n",
    "    change_output_wrt_weighted_hidden_layer_activation = derivative_sigmoid(output)\n",
    "\n",
    "\n",
    "        # step 2.3 - change in weighted_hidden_layer_activation wrt who\n",
    "\n",
    "    change_weighted_hidden_layer_activation_wrt_who = hiddenlayer_activations\n",
    "\n",
    "\n",
    "        # step 2.4 - calculate change in error with respect to who\n",
    "\n",
    "    delta_who = np.dot(change_weighted_hidden_layer_activation_wrt_who.T, change_error_output * change_output_wrt_weighted_hidden_layer_activation)\n",
    "\n",
    "    # step 3 - find change in error with respect to bho\n",
    "        # step 3.1 - change in error with respect to output \n",
    "\n",
    "    # (already calculated in step 1.1)\n",
    "\n",
    "        # step 3.2 - change in output wrt weighted_hidden_layer_activation \n",
    "\n",
    "    # (already calculated in step 1.2)\n",
    "\n",
    "\n",
    "\n",
    "        # step 3.3 - change in weighted_hidden_layer_activation wrt bho\n",
    "\n",
    "    change_weighted_hidden_layer_activation_wrt_bho = np.array([[1], [1], [1]])\n",
    "\n",
    "\n",
    "\n",
    "        # step 3.4 - calculate change in error with respect to who\n",
    "\n",
    "    delta_bho = np.dot(change_weighted_hidden_layer_activation_wrt_bho.T, change_error_output * change_output_wrt_weighted_hidden_layer_activation)\n",
    "\n",
    "\n",
    "\n",
    "    # step 4 - change in error wrt wih\n",
    "        # step 4.1 - change in error with respect to output \n",
    "\n",
    "    # (already calculated in step 1.1)\n",
    "\n",
    "        # step 4.2 - change in output wrt weighted_hidden_layer_activation \n",
    "\n",
    "    # (already calculated in step 1.2)\n",
    "\n",
    "\n",
    "\n",
    "        # step 4.3 - change in weighted_hidden_layer_activation wrt hidden_layer_activation\n",
    "\n",
    "    change_weighted_hidden_layer_activation_wrt_hidden_layer_activation = who\n",
    "\n",
    "\n",
    "        # step 4.4 - change in hidden_layer_activation wrt weighted_input\n",
    "\n",
    "    change_hidden_layer_activation_wrt_weighted_input = derivative_sigmoid(hiddenlayer_activations)\n",
    "\n",
    "\n",
    "        # step 4.5 - change in weighted_input wrt wih\n",
    "\n",
    "    change_weighted_input_wrt_wih = X\n",
    "\n",
    "\n",
    "        # step 4.6 - calculate error wrt wih\n",
    "\n",
    "    delta_wih = np.dot(change_weighted_input_wrt_wih.T, (change_hidden_layer_activation_wrt_weighted_input * (change_error_output * change_output_wrt_weighted_hidden_layer_activation).dot(change_weighted_hidden_layer_activation_wrt_hidden_layer_activation.T)))\n",
    "\n",
    "    # step 5 - change in error wrt bih\n",
    "        # step 5.1 - change in error with respect to output \n",
    "\n",
    "    # (already calculated in step 1.1)\n",
    "\n",
    "\n",
    "\n",
    "        # step 5.2 - change in output wrt weighted_hidden_layer_activation \n",
    "\n",
    "    # (already calculated in step 1.2)\n",
    "\n",
    "        # step 5.3 - change in weighted_hidden_layer_activation wrt hidden_layer_activation \n",
    "\n",
    "    # (already calculated in step 4.1.3)\n",
    "\n",
    "        # step 5.4 - change in hidden_layer_activation wrt weighted_input\n",
    "\n",
    "    # (already calculated in step 4.2)\n",
    "\n",
    "        # step 5.5 - change in weighted_input wrt bih\n",
    "\n",
    "    change_weighted_input_wrt_bih = np.array([[1.], [1.], [1.]])\n",
    "\n",
    "        # step 5.6 - calculate error wrt bih\n",
    "\n",
    "    delta_bih = np.dot(change_weighted_input_wrt_bih.T, (change_hidden_layer_activation_wrt_weighted_input * (change_error_output * change_output_wrt_weighted_hidden_layer_activation).dot(change_weighted_hidden_layer_activation_wrt_hidden_layer_activation.T)))\n",
    "\n",
    "    # step 6 - update who, wih, bho, bih\n",
    "        # step 6.1 - who is updated with a part of change in error wrt who\n",
    "    who += delta_who * 0.1\n",
    "\n",
    "        # step 6.2 - wih is updated with a part of change in error wrt wih\n",
    "    wih += delta_wih * 0.1\n",
    "\n",
    "        # step 6.3 - bho is updated with a part of change in error wrt bho\n",
    "    bho += delta_bho * 0.1\n",
    "\n",
    "        # step 6.4 - bih is updated with a part of change in error wrt bih\n",
    "    bih += delta_bih * 0.1\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the structure of neural network\n",
    "\n",
    "# define the number of neurons at input, hidden and output layer\n",
    "# initialize weights and biases for edges between input and hidden layer\n",
    "# initialize weights and biases for edges between hidden and output layer\n",
    "# define activation functions for hidden and output layer\n",
    "# define derivative of activation functions for hidden and output layers\n",
    "\n",
    "## Forward Propagation\n",
    "# multiply input with weight matrix (input and hidden layer)\n",
    "# apply activation function on weighted input\n",
    "# multiply hidden layer activations with weight matrix (hidden and output layer)\n",
    "# apply activation function on weighted hidden layer activations\n",
    "\n",
    "## BackPropagation\n",
    "# calculate error\n",
    "# calculate change in error with respect to who\n",
    "# calculate change in error with respect to bho\n",
    "# calculate change in error with respect to wih\n",
    "# calculate change in error with respect to bih\n",
    "# update who, wih, bho, bih\n",
    "\n",
    "# repeat forward and backward propagation for more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
