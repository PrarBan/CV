{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, InputLayer, \\\n",
    "    Convolution2D, MaxPooling2D, Flatten,   \\\n",
    "    Dropout, BatchNormalization, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/emergency_classification/emergency_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>emergency_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_names  emergency_or_not\n",
       "0       0.jpg                 1\n",
       "1       1.jpg                 1\n",
       "2       2.jpg                 1\n",
       "3       3.jpg                 1\n",
       "4       4.jpg                 1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1361\n",
       "1     991\n",
       "Name: emergency_or_not, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emergency_or_not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at random Emergency Vehicles\n",
    "\n",
    "emergency_vehicles = data.loc[data['emergency_or_not']==1,\"image_names\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for img_loc in data.image_names:\n",
    "    img = image.load_img('../datasets/emergency_classification/images/' + img_loc)\n",
    "    img = image.img_to_array(img)\n",
    "    images.append(img)\n",
    "    \n",
    "images=np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = images / images.max()\n",
    "train_y = data.emergency_or_not.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid=train_test_split(train_x,train_y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    " InputLayer(input_shape=(224, 224, 3)),\n",
    "\n",
    " Convolution2D(32, (5, 5), activation='relu', padding='same'),\n",
    " MaxPooling2D(pool_size=2),\n",
    " BatchNormalization(),\n",
    "\n",
    " Convolution2D(64, (5, 5), activation='relu', padding='same'),\n",
    " Convolution2D(64, (5, 5), activation='relu', padding='same'),\n",
    " MaxPooling2D(pool_size=2),\n",
    " BatchNormalization(),\n",
    "\n",
    " Convolution2D(128, (5, 5), activation='relu', padding='same'),\n",
    " Convolution2D(128, (5, 5), activation='relu', padding='same'),\n",
    " MaxPooling2D(pool_size=2),\n",
    " BatchNormalization(),\n",
    "    \n",
    " Convolution2D(256, (5, 5), activation='relu', padding='same'),\n",
    " Convolution2D(256, (5, 5), activation='relu', padding='same'),\n",
    " MaxPooling2D(pool_size=2),\n",
    " BatchNormalization(),\n",
    "    \n",
    " Convolution2D(512, (5, 5), activation='relu', padding='same'),\n",
    " Convolution2D(512, (5, 5), activation='relu', padding='same'),\n",
    "\n",
    " GlobalAveragePooling2D(),\n",
    " BatchNormalization(),\n",
    "\n",
    " Dense(units=512, activation='sigmoid'),\n",
    " BatchNormalization(),\n",
    " Dropout(0.5),\n",
    "    \n",
    " Dense(units=1, activation='sigmoid', name = 'preds'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 112, 112, 64)      51264     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 112, 112, 64)      102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 56, 56, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 56, 56, 128)       409728    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 256)       819456    \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 14, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,329,537\n",
      "Trainable params: 13,326,529\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator(\n",
    "    width_shift_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weights_path = '../models/best_cnn_model.h5'\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(final_weights_path, monitor='val_loss', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "412/412 [==============================] - 27s 67ms/step - loss: 0.9213 - acc: 0.5267 - val_loss: 0.7031 - val_acc: 0.5722\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70315, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 2/60\n",
      "412/412 [==============================] - 23s 56ms/step - loss: 0.8003 - acc: 0.5692 - val_loss: 0.7644 - val_acc: 0.4278\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.70315\n",
      "Epoch 3/60\n",
      "412/412 [==============================] - 23s 57ms/step - loss: 0.7585 - acc: 0.5868 - val_loss: 0.6845 - val_acc: 0.5567\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70315 to 0.68448, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 4/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.7375 - acc: 0.5910 - val_loss: 0.7045 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.68448\n",
      "Epoch 5/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.7127 - acc: 0.5922 - val_loss: 0.7224 - val_acc: 0.5623\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.68448\n",
      "Epoch 6/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.7326 - acc: 0.5661 - val_loss: 0.6524 - val_acc: 0.6161\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68448 to 0.65237, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 7/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.7207 - acc: 0.5874 - val_loss: 0.7973 - val_acc: 0.5581\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.65237\n",
      "Epoch 8/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6836 - acc: 0.6177 - val_loss: 0.6694 - val_acc: 0.6176\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.65237\n",
      "Epoch 9/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.6766 - acc: 0.6123 - val_loss: 0.6347 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.65237 to 0.63474, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 10/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6718 - acc: 0.6305 - val_loss: 0.7769 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.63474\n",
      "Epoch 11/60\n",
      "412/412 [==============================] - 25s 62ms/step - loss: 0.6574 - acc: 0.6529 - val_loss: 0.6890 - val_acc: 0.5779\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.63474\n",
      "Epoch 12/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.7076 - acc: 0.5643 - val_loss: 0.6441 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.63474\n",
      "Epoch 13/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6933 - acc: 0.5983 - val_loss: 0.6998 - val_acc: 0.5382\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.63474\n",
      "Epoch 14/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6955 - acc: 0.5868 - val_loss: 0.6823 - val_acc: 0.6006\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.63474\n",
      "Epoch 15/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6740 - acc: 0.6129 - val_loss: 0.6235 - val_acc: 0.6756\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.63474 to 0.62353, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 16/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6557 - acc: 0.6371 - val_loss: 0.6298 - val_acc: 0.6799\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.62353\n",
      "Epoch 17/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6406 - acc: 0.6547 - val_loss: 0.6655 - val_acc: 0.6402\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.62353\n",
      "Epoch 18/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6366 - acc: 0.6608 - val_loss: 0.5931 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.62353 to 0.59305, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 19/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.6388 - acc: 0.6523 - val_loss: 0.6144 - val_acc: 0.6516\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.59305\n",
      "Epoch 20/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.6284 - acc: 0.6529 - val_loss: 0.5981 - val_acc: 0.6912\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.59305\n",
      "Epoch 21/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.6234 - acc: 0.6784 - val_loss: 0.6494 - val_acc: 0.6615\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.59305\n",
      "Epoch 22/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.6165 - acc: 0.6839 - val_loss: 0.5580 - val_acc: 0.7252\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.59305 to 0.55800, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 23/60\n",
      "412/412 [==============================] - 25s 62ms/step - loss: 0.6320 - acc: 0.6735 - val_loss: 0.5389 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.55800 to 0.53888, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 24/60\n",
      "412/412 [==============================] - 25s 62ms/step - loss: 0.5859 - acc: 0.7063 - val_loss: 0.5742 - val_acc: 0.7394\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.53888\n",
      "Epoch 25/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5807 - acc: 0.7057 - val_loss: 0.5486 - val_acc: 0.7351\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.53888\n",
      "Epoch 26/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5944 - acc: 0.7033 - val_loss: 0.5399 - val_acc: 0.7635\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.53888\n",
      "Epoch 27/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5718 - acc: 0.7106 - val_loss: 0.5842 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.53888\n",
      "Epoch 28/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.5912 - acc: 0.6948 - val_loss: 0.4969 - val_acc: 0.7578\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.53888 to 0.49693, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 29/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.5837 - acc: 0.7106 - val_loss: 0.5456 - val_acc: 0.7394\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.49693\n",
      "Epoch 30/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.5815 - acc: 0.7124 - val_loss: 0.5683 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.49693\n",
      "Epoch 31/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5617 - acc: 0.7348 - val_loss: 0.6186 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.49693\n",
      "Epoch 32/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.5461 - acc: 0.7470 - val_loss: 0.5918 - val_acc: 0.6544\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.49693\n",
      "Epoch 33/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5429 - acc: 0.7409 - val_loss: 0.4486 - val_acc: 0.7975\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.49693 to 0.44858, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 34/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5427 - acc: 0.7397 - val_loss: 0.4968 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.44858\n",
      "Epoch 35/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.5252 - acc: 0.7542 - val_loss: 0.5754 - val_acc: 0.7054\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.44858\n",
      "Epoch 36/60\n",
      "412/412 [==============================] - 25s 62ms/step - loss: 0.5041 - acc: 0.7664 - val_loss: 0.4447 - val_acc: 0.8003\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.44858 to 0.44472, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 37/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5168 - acc: 0.7512 - val_loss: 0.6020 - val_acc: 0.6572\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.44472\n",
      "Epoch 38/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.5135 - acc: 0.7585 - val_loss: 0.4863 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.44472\n",
      "Epoch 39/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.5024 - acc: 0.7761 - val_loss: 0.4810 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.44472\n",
      "Epoch 40/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.4966 - acc: 0.7573 - val_loss: 0.4030 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.44472 to 0.40299, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 41/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.5087 - acc: 0.7609 - val_loss: 0.4930 - val_acc: 0.7875\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.40299\n",
      "Epoch 42/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 25s 61ms/step - loss: 0.4723 - acc: 0.7755 - val_loss: 0.5109 - val_acc: 0.7663\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.40299\n",
      "Epoch 43/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.4603 - acc: 0.7955 - val_loss: 0.4481 - val_acc: 0.8074\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.40299\n",
      "Epoch 44/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.4743 - acc: 0.7816 - val_loss: 0.4467 - val_acc: 0.8258\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.40299\n",
      "Epoch 45/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.4380 - acc: 0.8058 - val_loss: 0.4271 - val_acc: 0.8258\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.40299\n",
      "Epoch 46/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.4590 - acc: 0.7828 - val_loss: 0.4522 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.40299\n",
      "Epoch 47/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.4728 - acc: 0.7834 - val_loss: 0.4184 - val_acc: 0.8343\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.40299\n",
      "Epoch 48/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.4658 - acc: 0.7907 - val_loss: 0.4870 - val_acc: 0.7946\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.40299\n",
      "Epoch 49/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.4434 - acc: 0.8089 - val_loss: 0.3825 - val_acc: 0.8626\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.40299 to 0.38250, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 50/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.4195 - acc: 0.8131 - val_loss: 0.3702 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.38250 to 0.37020, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 51/60\n",
      "412/412 [==============================] - 25s 62ms/step - loss: 0.4328 - acc: 0.8174 - val_loss: 0.4766 - val_acc: 0.7805\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.37020\n",
      "Epoch 52/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.4200 - acc: 0.8131 - val_loss: 0.4050 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.37020\n",
      "Epoch 53/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.4372 - acc: 0.8083 - val_loss: 0.4822 - val_acc: 0.8003\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.37020\n",
      "Epoch 54/60\n",
      "412/412 [==============================] - 25s 61ms/step - loss: 0.4384 - acc: 0.7992 - val_loss: 0.3727 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.37020\n",
      "Epoch 55/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.4283 - acc: 0.8137 - val_loss: 0.3972 - val_acc: 0.8357\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.37020\n",
      "Epoch 56/60\n",
      "412/412 [==============================] - 25s 62ms/step - loss: 0.3959 - acc: 0.8441 - val_loss: 0.4185 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.37020\n",
      "Epoch 57/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.3975 - acc: 0.8356 - val_loss: 0.4294 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.37020\n",
      "Epoch 58/60\n",
      "412/412 [==============================] - 25s 60ms/step - loss: 0.4283 - acc: 0.8052 - val_loss: 0.3433 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.37020 to 0.34333, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 59/60\n",
      "412/412 [==============================] - 26s 62ms/step - loss: 0.4092 - acc: 0.8216 - val_loss: 0.3515 - val_acc: 0.8569\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34333\n",
      "Epoch 60/60\n",
      "412/412 [==============================] - 24s 59ms/step - loss: 0.3773 - acc: 0.8465 - val_loss: 0.4304 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=4),epochs=60,validation_data=(X_valid,Y_valid), callbacks=callbacks_list, shuffle=False, workers=5, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(final_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_valid).ravel()\n",
    "prediction_probabilities = model.predict(X_valid).ravel()\n",
    "all_vehicles = np.array(emergency_vehicles + nonemergency_vehicles)\n",
    "\n",
    "_, valid_vehicles, _, valid_y = train_test_split(all_vehicles,train_y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = valid_vehicles[predictions == Y_valid]\n",
    "\n",
    "index = rng.choice(range(len(correct_predictions)))\n",
    "img_name = correct_predictions[index]\n",
    "\n",
    "\n",
    "prob = (prediction_probabilities[predictions == Y_valid] * 100).astype(int)[index]\n",
    "\n",
    "img = imread('../datasets/emergency_classification/images/' + img_name)\n",
    "\n",
    "print(prob , '% sure that it is emergency')\n",
    "pylab.imshow(img)\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_predictions = valid_vehicles[predictions != Y_valid]\n",
    "index = rng.choice(range(len(incorrect_predictions)))\n",
    "img_name = incorrect_predictions[index]\n",
    "\n",
    "\n",
    "prob = (prediction_probabilities[predictions != Y_valid] * 100).astype(int)[index]\n",
    "\n",
    "img = imread('../datasets/emergency_classification/images/' + img_name)\n",
    "\n",
    "print(prob , '% sure that it is emergency')\n",
    "pylab.imshow(img)\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(predictions, Y_valid).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, tp, fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(predictions, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer = model.layers[0]\n",
    "plt.imshow(top_layer.get_weights()[0][:, :, :, 0].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.abs(top_layer.get_weights()[0][:, :, :, 0].squeeze().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(top_layer.get_weights()[0][:, :, :, 0].squeeze() + min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_activation\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "layer_idx = -1\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "\n",
    "# This is the output node we want to maximize.\n",
    "filter_idx = 0\n",
    "img = visualize_activation(model, layer_idx, filter_indices=filter_idx)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from vis.visualization import get_num_filters\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# You can see this in the model definition.\n",
    "layer_idx = 4\n",
    "\n",
    "# Visualize all filters in this layer.\n",
    "filters = np.arange(get_num_filters(model.layers[layer_idx]))\n",
    "\n",
    "# Generate input image for each filter.\n",
    "vis_images = []\n",
    "for idx in filters[:4]:\n",
    "    img = visualize_activation(model, layer_idx, filter_indices=idx)\n",
    "    \n",
    "    # Utility to overlay text on image.\n",
    "    img = utils.draw_text(img, 'Filter {}'.format(idx))    \n",
    "    vis_images.append(img)\n",
    "\n",
    "# Generate stitched image palette with 8 cols.\n",
    "stitched = utils.stitch_images(vis_images, cols=8)    \n",
    "plt.axis('off')\n",
    "plt.imshow(stitched)\n",
    "plt.title(layer_idx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = rng.choice(emergency_vehicles)\n",
    "\n",
    "img = imread('../datasets/emergency_classification/images/' +img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from vis.visualization import visualize_cam\n",
    "from vis.visualization import visualize_saliency, overlay\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "f, ax = plt.subplots()\n",
    "plt.suptitle(\"vanilla\")\n",
    "\n",
    "grads = visualize_cam(model, -1, filter_indices=0, \n",
    "                      seed_input=img, backprop_modifier=None)        \n",
    "# Lets overlay the heatmap onto original image.    \n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "ax.imshow(overlay(jet_heatmap, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in emergency_vehicles:\n",
    "    img = imread('../datasets/emergency_classification/images/' + img_name)\n",
    "    \n",
    "    plt.figure()\n",
    "    f, ax = plt.subplots()\n",
    "    plt.suptitle(\"vanilla\")\n",
    "\n",
    "    grads = visualize_cam(model, -1, filter_indices=0, \n",
    "                          seed_input=img, backprop_modifier=None)        \n",
    "    # Lets overlay the heatmap onto original image.    \n",
    "    jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "    ax.imshow(overlay(jet_heatmap, img))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = glob('../datasets/emergency_classification/images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = vehicles[285]\n",
    "img = imread(img_name)\n",
    "\n",
    "plt.figure()\n",
    "f, ax = plt.subplots()\n",
    "plt.suptitle(\"vanilla\")\n",
    "\n",
    "grads = visualize_cam(model, -1, filter_indices=0, \n",
    "                      seed_input=img, backprop_modifier=None)        \n",
    "# Lets overlay the heatmap onto original image.    \n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "ax.imshow(overlay(jet_heatmap, img))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
