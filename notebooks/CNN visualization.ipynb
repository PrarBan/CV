{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, InputLayer, \\\n",
    "    Convolution2D, MaxPooling2D, Flatten,   \\\n",
    "    Dropout, BatchNormalization, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/male_vs_female_classification/male_vs_female_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1267.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1268.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1269.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1270.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1271.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  class\n",
       "0   1267.jpg      1\n",
       "1   1268.jpg      1\n",
       "2   1269.jpg      1\n",
       "3   1270.jpg      1\n",
       "4   1271.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8853\n",
       "0    8570\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for img_loc in data.image_name:\n",
    "    img = image.load_img('../datasets/male_vs_female_classification/images/' + img_loc)\n",
    "    img = image.img_to_array(img)\n",
    "    images.append(img)\n",
    "    \n",
    "images=np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17423, 224, 224, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = images / images.max()\n",
    "train_y = data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid=train_test_split(train_x,train_y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    " InputLayer(input_shape=(224, 224, 3)),\n",
    "\n",
    " Convolution2D(32, (5, 5), activation='relu', padding='same', name = \"block1_conv1\"),\n",
    " MaxPooling2D(pool_size=2, name = \"block1_pool\"),\n",
    " BatchNormalization(name = \"block1_batchnorm\"),\n",
    "\n",
    " Convolution2D(64, (5, 5), activation='relu', padding='same', name = \"block2_conv1\"),\n",
    " Convolution2D(64, (5, 5), activation='relu', padding='same', name = \"block2_conv2\"),\n",
    " MaxPooling2D(pool_size=2, name = \"block2_pool\"),\n",
    " BatchNormalization(name = \"block2_batchnorm\"),\n",
    "\n",
    " Convolution2D(128, (5, 5), activation='relu', padding='same', name = \"block3_conv1\"),\n",
    " Convolution2D(128, (5, 5), activation='relu', padding='same', name = \"block3_conv2\"),\n",
    " MaxPooling2D(pool_size=2, name = \"block3_pool\"),\n",
    " BatchNormalization(name = \"block3_batchnorm\"),\n",
    "    \n",
    " Convolution2D(256, (5, 5), activation='relu', padding='same', name = \"block4_conv1\"),\n",
    " Convolution2D(256, (5, 5), activation='relu', padding='same', name = \"block4_conv2\"),\n",
    " MaxPooling2D(pool_size=2, name = \"block4_pool\"),\n",
    " BatchNormalization(name = \"block4_batchnorm\"),\n",
    "    \n",
    " Convolution2D(512, (5, 5), activation='relu', padding='same', name = \"block5_conv1\"),\n",
    " Convolution2D(512, (5, 5), activation='relu', padding='same', name = \"block5_conv2\"),  \n",
    " MaxPooling2D(pool_size=2, name = \"block5_pool\"),\n",
    "\n",
    "\n",
    " GlobalAveragePooling2D(),\n",
    " BatchNormalization(),\n",
    "\n",
    " Dense(units=512, activation='sigmoid', name = 'fc1'),\n",
    " BatchNormalization(),\n",
    " Dropout(0.5),\n",
    "    \n",
    " Dense(units=1, activation='sigmoid', name = 'predictions'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "block1_batchnorm (BatchNorma (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 64)      51264     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 64)      102464    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_batchnorm (BatchNorma (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 128)       204928    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 128)       409728    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_batchnorm (BatchNorma (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 256)       819456    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_batchnorm (BatchNorma (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,329,537\n",
      "Trainable params: 13,326,529\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator()\n",
    "#     width_shift_range = 0.2,\n",
    "#     horizontal_flip = True,\n",
    "#     height_shift_range = 0.2,\n",
    "#     rotation_range = 20\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_weights_path = '../models/best_cnn_model.h5'\n",
    "\n",
    "callbacks_list = [\n",
    "    ModelCheckpoint(final_weights_path, monitor='val_loss', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48/48 [==============================] - 80s 2s/step - loss: 0.9975 - acc: 0.5470 - val_loss: 1.1092 - val_acc: 0.5091\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.10923, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 2/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.7202 - acc: 0.6384 - val_loss: 0.5810 - val_acc: 0.7084\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.10923 to 0.58098, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 3/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.5743 - acc: 0.7295 - val_loss: 0.8810 - val_acc: 0.5799\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.58098\n",
      "Epoch 4/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.4965 - acc: 0.7697 - val_loss: 0.8868 - val_acc: 0.6964\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.58098\n",
      "Epoch 5/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.4064 - acc: 0.8124 - val_loss: 0.7282 - val_acc: 0.7207\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.58098\n",
      "Epoch 6/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.3399 - acc: 0.8499 - val_loss: 0.4769 - val_acc: 0.7794\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.58098 to 0.47689, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 7/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.3060 - acc: 0.8662 - val_loss: 0.4505 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47689 to 0.45048, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 8/100\n",
      "48/48 [==============================] - 58s 1s/step - loss: 0.2665 - acc: 0.8826 - val_loss: 0.2916 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.45048 to 0.29163, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 9/100\n",
      "48/48 [==============================] - 58s 1s/step - loss: 0.2204 - acc: 0.9078 - val_loss: 0.4662 - val_acc: 0.8049\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.29163\n",
      "Epoch 10/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.2080 - acc: 0.9128 - val_loss: 0.3920 - val_acc: 0.8412\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.29163\n",
      "Epoch 11/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.1888 - acc: 0.9223 - val_loss: 0.6354 - val_acc: 0.8106\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.29163\n",
      "Epoch 12/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.1706 - acc: 0.9310 - val_loss: 0.3651 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.29163\n",
      "Epoch 13/100\n",
      "48/48 [==============================] - 58s 1s/step - loss: 0.1486 - acc: 0.9398 - val_loss: 0.2152 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.29163 to 0.21519, saving model to ../models/best_cnn_model.h5\n",
      "Epoch 14/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.1318 - acc: 0.9455 - val_loss: 0.2277 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.21519\n",
      "Epoch 15/100\n",
      "48/48 [==============================] - 59s 1s/step - loss: 0.1262 - acc: 0.9472 - val_loss: 0.3503 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.21519\n",
      "Epoch 16/100\n",
      " 3/48 [>.............................] - ETA: 41s - loss: 0.1063 - acc: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-311:\n",
      "Process ForkPoolWorker-318:\n",
      "Process ForkPoolWorker-314:\n",
      "Process ForkPoolWorker-312:\n",
      "Process ForkPoolWorker-308:\n",
      "Process ForkPoolWorker-302:\n",
      "Process ForkPoolWorker-310:\n",
      "Process ForkPoolWorker-304:\n",
      "Process ForkPoolWorker-301:\n",
      "Process ForkPoolWorker-313:\n",
      "Process ForkPoolWorker-307:\n",
      "Process ForkPoolWorker-305:\n",
      "Process ForkPoolWorker-316:\n",
      "Process ForkPoolWorker-309:\n",
      "Process ForkPoolWorker-320:\n",
      "Process ForkPoolWorker-317:\n",
      "Process ForkPoolWorker-306:\n",
      "Process ForkPoolWorker-303:\n",
      "Process ForkPoolWorker-319:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-315:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b6422b421ab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=256),epochs=100,validation_data=(X_valid,Y_valid), callbacks=callbacks_list, shuffle=False, workers=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(final_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "block1_batchnorm (BatchNorma (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 64)      51264     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 64)      102464    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_batchnorm (BatchNorma (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 128)       204928    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 128)       409728    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_batchnorm (BatchNorma (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 256)       819456    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_batchnorm (BatchNorma (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,329,537\n",
      "Trainable params: 13,326,529\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 32)      2432      \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "block1_batchnorm (BatchNorma (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 64)      51264     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 64)      102464    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_batchnorm (BatchNorma (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 128)       204928    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 128)       409728    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_batchnorm (BatchNorma (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 256)       819456    \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_batchnorm (BatchNorma (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       6554112   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 13,327,489\n",
      "Trainable params: 13,326,529\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/keras/engine/training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'block5_conv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter 0\n",
      "Current loss value: 10880.925\n",
      "Current loss value: 11712.92\n",
      "Current loss value: 12561.908\n",
      "Current loss value: 13420.363\n",
      "Current loss value: 14301.216\n",
      "Current loss value: 15180.873\n",
      "Current loss value: 16056.887\n",
      "Current loss value: 16931.324\n",
      "Current loss value: 17799.871\n",
      "Current loss value: 18660.68\n",
      "Current loss value: 19523.162\n",
      "Current loss value: 20384.086\n",
      "Current loss value: 21246.86\n",
      "Current loss value: 22109.459\n",
      "Current loss value: 22970.13\n",
      "Current loss value: 23826.2\n",
      "Current loss value: 24683.033\n",
      "Current loss value: 25545.3\n",
      "Current loss value: 26414.48\n",
      "Current loss value: 27285.38\n",
      "Filter 0 processed in 0s\n",
      "Processing filter 1\n",
      "Current loss value: 19148.1\n",
      "Current loss value: 20184.178\n",
      "Current loss value: 21263.336\n",
      "Current loss value: 22365.0\n",
      "Current loss value: 23510.027\n",
      "Current loss value: 24665.502\n",
      "Current loss value: 25820.307\n",
      "Current loss value: 26960.574\n",
      "Current loss value: 28087.309\n",
      "Current loss value: 29208.0\n",
      "Current loss value: 30309.457\n",
      "Current loss value: 31411.324\n",
      "Current loss value: 32511.166\n",
      "Current loss value: 33611.465\n",
      "Current loss value: 34708.617\n",
      "Current loss value: 35803.25\n",
      "Current loss value: 36890.938\n",
      "Current loss value: 37973.258\n",
      "Current loss value: 39061.39\n",
      "Current loss value: 40154.223\n",
      "Filter 1 processed in 0s\n",
      "Processing filter 2\n",
      "Current loss value: 0.0\n",
      "Filter 2 processed in 0s\n",
      "Processing filter 3\n",
      "Current loss value: 3659.4365\n",
      "Current loss value: 3841.1963\n",
      "Current loss value: 4029.6528\n",
      "Current loss value: 4223.3574\n",
      "Current loss value: 4421.8525\n",
      "Current loss value: 4615.8765\n",
      "Current loss value: 4809.3477\n",
      "Current loss value: 5000.7446\n",
      "Current loss value: 5191.199\n",
      "Current loss value: 5383.5596\n",
      "Current loss value: 5575.461\n",
      "Current loss value: 5764.071\n",
      "Current loss value: 5950.5396\n",
      "Current loss value: 6138.7544\n",
      "Current loss value: 6326.5796\n",
      "Current loss value: 6513.925\n",
      "Current loss value: 6702.3867\n",
      "Current loss value: 6890.467\n",
      "Current loss value: 7077.994\n",
      "Current loss value: 7264.657\n",
      "Filter 3 processed in 0s\n",
      "Processing filter 4\n",
      "Current loss value: 9456.376\n",
      "Current loss value: 10189.342\n",
      "Current loss value: 10936.585\n",
      "Current loss value: 11701.383\n",
      "Current loss value: 12488.887\n",
      "Current loss value: 13274.8125\n",
      "Current loss value: 14052.998\n",
      "Current loss value: 14822.955\n",
      "Current loss value: 15583.363\n",
      "Current loss value: 16342.433\n",
      "Current loss value: 17098.371\n",
      "Current loss value: 17851.375\n",
      "Current loss value: 18600.533\n",
      "Current loss value: 19350.127\n",
      "Current loss value: 20100.523\n",
      "Current loss value: 20850.385\n",
      "Current loss value: 21598.941\n",
      "Current loss value: 22349.143\n",
      "Current loss value: 23101.639\n",
      "Current loss value: 23852.363\n",
      "Filter 4 processed in 0s\n",
      "Processing filter 5\n",
      "Current loss value: 0.0\n",
      "Filter 5 processed in 0s\n",
      "Processing filter 6\n",
      "Current loss value: 0.0\n",
      "Filter 6 processed in 0s\n",
      "Processing filter 7\n",
      "Current loss value: 0.0\n",
      "Filter 7 processed in 0s\n",
      "Processing filter 8\n",
      "Current loss value: 0.0\n",
      "Filter 8 processed in 0s\n",
      "Processing filter 9\n",
      "Current loss value: 0.0\n",
      "Filter 9 processed in 0s\n",
      "Processing filter 10\n",
      "Current loss value: 1257.6282\n",
      "Current loss value: 1434.6018\n",
      "Current loss value: 1611.2601\n",
      "Current loss value: 1783.7888\n",
      "Current loss value: 1949.1855\n",
      "Current loss value: 2106.8728\n",
      "Current loss value: 2253.3108\n",
      "Current loss value: 2393.7559\n",
      "Current loss value: 2530.004\n",
      "Current loss value: 2663.4766\n",
      "Current loss value: 2793.1409\n",
      "Current loss value: 2921.4258\n",
      "Current loss value: 3048.9028\n",
      "Current loss value: 3176.3257\n",
      "Current loss value: 3304.2097\n",
      "Current loss value: 3433.183\n",
      "Current loss value: 3561.5295\n",
      "Current loss value: 3689.6592\n",
      "Current loss value: 3819.3508\n",
      "Current loss value: 3948.837\n",
      "Filter 10 processed in 0s\n",
      "Processing filter 11\n",
      "Current loss value: 0.0\n",
      "Filter 11 processed in 0s\n",
      "Processing filter 12\n",
      "Current loss value: 0.0\n",
      "Filter 12 processed in 0s\n",
      "Processing filter 13\n",
      "Current loss value: 456.61932\n",
      "Current loss value: 530.89087\n",
      "Current loss value: 607.2766\n",
      "Current loss value: 689.5991\n",
      "Current loss value: 780.8168\n",
      "Current loss value: 878.36426\n",
      "Current loss value: 984.96594\n",
      "Current loss value: 1094.4465\n",
      "Current loss value: 1210.406\n",
      "Current loss value: 1334.8373\n",
      "Current loss value: 1459.0588\n",
      "Current loss value: 1588.8857\n",
      "Current loss value: 1720.3754\n",
      "Current loss value: 1853.5244\n",
      "Current loss value: 1992.4683\n",
      "Current loss value: 2139.8416\n",
      "Current loss value: 2292.9888\n",
      "Current loss value: 2448.1243\n",
      "Current loss value: 2612.959\n",
      "Current loss value: 2786.2607\n",
      "Filter 13 processed in 0s\n",
      "Processing filter 14\n",
      "Current loss value: 4900.0137\n",
      "Current loss value: 5523.1816\n",
      "Current loss value: 6149.1533\n",
      "Current loss value: 6803.9277\n",
      "Current loss value: 7471.682\n",
      "Current loss value: 8134.693\n",
      "Current loss value: 8803.191\n",
      "Current loss value: 9481.977\n",
      "Current loss value: 10170.883\n",
      "Current loss value: 10858.623\n",
      "Current loss value: 11543.426\n",
      "Current loss value: 12226.572\n",
      "Current loss value: 12915.365\n",
      "Current loss value: 13605.271\n",
      "Current loss value: 14300.867\n",
      "Current loss value: 14992.813\n",
      "Current loss value: 15685.379\n",
      "Current loss value: 16379.354\n",
      "Current loss value: 17070.45\n",
      "Current loss value: 17762.97\n",
      "Filter 14 processed in 0s\n",
      "Processing filter 15\n",
      "Current loss value: 5796.9507\n",
      "Current loss value: 6271.125\n",
      "Current loss value: 6740.6265\n",
      "Current loss value: 7203.3926\n",
      "Current loss value: 7671.96\n",
      "Current loss value: 8142.3047\n",
      "Current loss value: 8619.301\n",
      "Current loss value: 9089.905\n",
      "Current loss value: 9554.832\n",
      "Current loss value: 10011.826\n",
      "Current loss value: 10467.366\n",
      "Current loss value: 10922.312\n",
      "Current loss value: 11373.0\n",
      "Current loss value: 11825.006\n",
      "Current loss value: 12272.753\n",
      "Current loss value: 12719.152\n",
      "Current loss value: 13164.638\n",
      "Current loss value: 13609.92\n",
      "Current loss value: 14054.075\n",
      "Current loss value: 14495.508\n",
      "Filter 15 processed in 0s\n",
      "Processing filter 16\n",
      "Current loss value: 0.0\n",
      "Filter 16 processed in 0s\n",
      "Processing filter 17\n",
      "Current loss value: 0.0\n",
      "Filter 17 processed in 0s\n",
      "Processing filter 18\n",
      "Current loss value: 0.0\n",
      "Filter 18 processed in 0s\n",
      "Processing filter 19\n",
      "Current loss value: 4813.195\n",
      "Current loss value: 4937.2744\n",
      "Current loss value: 5068.4233\n",
      "Current loss value: 5201.3193\n",
      "Current loss value: 5332.6343\n",
      "Current loss value: 5459.936\n",
      "Current loss value: 5584.11\n",
      "Current loss value: 5703.711\n",
      "Current loss value: 5828.0264\n",
      "Current loss value: 5951.853\n",
      "Current loss value: 6074.9795\n",
      "Current loss value: 6199.333\n",
      "Current loss value: 6320.9414\n",
      "Current loss value: 6445.905\n",
      "Current loss value: 6569.685\n",
      "Current loss value: 6692.172\n",
      "Current loss value: 6819.907\n",
      "Current loss value: 6945.535\n",
      "Current loss value: 7079.81\n",
      "Current loss value: 7221.0557\n",
      "Filter 19 processed in 0s\n",
      "Processing filter 20\n",
      "Current loss value: 6050.2397\n",
      "Current loss value: 6210.8296\n",
      "Current loss value: 6384.3926\n",
      "Current loss value: 6553.507\n",
      "Current loss value: 6718.323\n",
      "Current loss value: 6882.1357\n",
      "Current loss value: 7040.3613\n",
      "Current loss value: 7198.537\n",
      "Current loss value: 7353.623\n",
      "Current loss value: 7509.3945\n",
      "Current loss value: 7668.162\n",
      "Current loss value: 7824.9697\n",
      "Current loss value: 7985.9375\n",
      "Current loss value: 8144.3975\n",
      "Current loss value: 8302.678\n",
      "Current loss value: 8452.361\n",
      "Current loss value: 8609.631\n",
      "Current loss value: 8765.701\n",
      "Current loss value: 8924.589\n",
      "Current loss value: 9085.751\n",
      "Filter 20 processed in 0s\n",
      "Processing filter 21\n",
      "Current loss value: 8615.703\n",
      "Current loss value: 8924.27\n",
      "Current loss value: 9269.479\n",
      "Current loss value: 9642.99\n",
      "Current loss value: 10043.352\n",
      "Current loss value: 10446.627\n",
      "Current loss value: 10852.055\n",
      "Current loss value: 11256.321\n",
      "Current loss value: 11655.453\n",
      "Current loss value: 12058.833\n",
      "Current loss value: 12465.35\n",
      "Current loss value: 12870.756\n",
      "Current loss value: 13279.189\n",
      "Current loss value: 13691.103\n",
      "Current loss value: 14104.791\n",
      "Current loss value: 14519.85\n",
      "Current loss value: 14939.387\n",
      "Current loss value: 15358.409\n",
      "Current loss value: 15777.9795\n",
      "Current loss value: 16201.269\n",
      "Filter 21 processed in 0s\n",
      "Processing filter 22\n",
      "Current loss value: 6358.904\n",
      "Current loss value: 6731.0137\n",
      "Current loss value: 7114.5825\n",
      "Current loss value: 7505.759\n",
      "Current loss value: 7908.1797\n",
      "Current loss value: 8312.127\n",
      "Current loss value: 8706.998\n",
      "Current loss value: 9094.029\n",
      "Current loss value: 9475.3\n",
      "Current loss value: 9852.58\n",
      "Current loss value: 10227.811\n",
      "Current loss value: 10601.282\n",
      "Current loss value: 10968.717\n",
      "Current loss value: 11331.795\n",
      "Current loss value: 11694.071\n",
      "Current loss value: 12056.461\n",
      "Current loss value: 12414.976\n",
      "Current loss value: 12773.102\n",
      "Current loss value: 13132.184\n",
      "Current loss value: 13491.691\n",
      "Filter 22 processed in 0s\n",
      "Processing filter 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 16.130344\n",
      "Current loss value: 41.294754\n",
      "Current loss value: 75.226944\n",
      "Current loss value: 118.236786\n",
      "Current loss value: 171.7281\n",
      "Current loss value: 238.88965\n",
      "Current loss value: 316.2468\n",
      "Current loss value: 397.75916\n",
      "Current loss value: 480.3407\n",
      "Current loss value: 565.2726\n",
      "Current loss value: 655.11\n",
      "Current loss value: 750.8903\n",
      "Current loss value: 850.2317\n",
      "Current loss value: 956.70154\n",
      "Current loss value: 1068.4634\n",
      "Current loss value: 1181.2532\n",
      "Current loss value: 1297.0522\n",
      "Current loss value: 1420.019\n",
      "Current loss value: 1546.4175\n",
      "Current loss value: 1675.4861\n",
      "Filter 23 processed in 0s\n",
      "Processing filter 24\n",
      "Current loss value: 17331.92\n",
      "Current loss value: 18476.965\n",
      "Current loss value: 19654.44\n",
      "Current loss value: 20879.385\n",
      "Current loss value: 22149.342\n",
      "Current loss value: 23425.63\n",
      "Current loss value: 24711.229\n",
      "Current loss value: 25995.102\n",
      "Current loss value: 27276.445\n",
      "Current loss value: 28556.715\n",
      "Current loss value: 29830.379\n",
      "Current loss value: 31103.934\n",
      "Current loss value: 32372.604\n",
      "Current loss value: 33639.96\n",
      "Current loss value: 34906.71\n",
      "Current loss value: 36168.555\n",
      "Current loss value: 37438.023\n",
      "Current loss value: 38715.51\n",
      "Current loss value: 39993.14\n",
      "Current loss value: 41270.836\n",
      "Filter 24 processed in 0s\n",
      "Processing filter 25\n",
      "Current loss value: 4260.9443\n",
      "Current loss value: 4649.1123\n",
      "Current loss value: 5046.8643\n",
      "Current loss value: 5441.245\n",
      "Current loss value: 5840.8584\n",
      "Current loss value: 6237.2383\n",
      "Current loss value: 6627.456\n",
      "Current loss value: 7007.33\n",
      "Current loss value: 7380.2534\n",
      "Current loss value: 7752.329\n",
      "Current loss value: 8119.575\n",
      "Current loss value: 8483.539\n",
      "Current loss value: 8845.945\n",
      "Current loss value: 9203.621\n",
      "Current loss value: 9562.083\n",
      "Current loss value: 9918.979\n",
      "Current loss value: 10275.588\n",
      "Current loss value: 10631.262\n",
      "Current loss value: 10990.15\n",
      "Current loss value: 11351.243\n",
      "Filter 25 processed in 0s\n",
      "Processing filter 26\n",
      "Current loss value: 6106.197\n",
      "Current loss value: 6765.4517\n",
      "Current loss value: 7413.8086\n",
      "Current loss value: 8072.4644\n",
      "Current loss value: 8739.158\n",
      "Current loss value: 9406.958\n",
      "Current loss value: 10074.235\n",
      "Current loss value: 10731.834\n",
      "Current loss value: 11383.075\n",
      "Current loss value: 12030.896\n",
      "Current loss value: 12684.022\n",
      "Current loss value: 13333.625\n",
      "Current loss value: 13977.834\n",
      "Current loss value: 14616.739\n",
      "Current loss value: 15255.66\n",
      "Current loss value: 15896.863\n",
      "Current loss value: 16533.533\n",
      "Current loss value: 17168.55\n",
      "Current loss value: 17805.89\n",
      "Current loss value: 18443.129\n",
      "Filter 26 processed in 0s\n",
      "Processing filter 27\n",
      "Current loss value: 0.18816806\n",
      "Current loss value: 5.0655684\n",
      "Current loss value: 9.3665085\n",
      "Current loss value: 12.087698\n",
      "Current loss value: 14.179364\n",
      "Current loss value: 15.705008\n",
      "Current loss value: 18.43322\n",
      "Current loss value: 21.505407\n",
      "Current loss value: 24.032291\n",
      "Current loss value: 27.17803\n",
      "Current loss value: 31.666151\n",
      "Current loss value: 35.42193\n",
      "Current loss value: 39.41606\n",
      "Current loss value: 44.261604\n",
      "Current loss value: 50.714973\n",
      "Current loss value: 58.26494\n",
      "Current loss value: 66.75899\n",
      "Current loss value: 74.410034\n",
      "Current loss value: 81.65771\n",
      "Current loss value: 88.73257\n",
      "Filter 27 processed in 1s\n",
      "Processing filter 28\n",
      "Current loss value: 444.18893\n",
      "Current loss value: 631.3195\n",
      "Current loss value: 831.6982\n",
      "Current loss value: 1041.8352\n",
      "Current loss value: 1248.6073\n",
      "Current loss value: 1455.2458\n",
      "Current loss value: 1669.6276\n",
      "Current loss value: 1885.5938\n",
      "Current loss value: 2099.0198\n",
      "Current loss value: 2310.048\n",
      "Current loss value: 2520.3535\n",
      "Current loss value: 2731.1096\n",
      "Current loss value: 2942.1187\n",
      "Current loss value: 3157.0254\n",
      "Current loss value: 3372.7708\n",
      "Current loss value: 3591.2915\n",
      "Current loss value: 3812.5916\n",
      "Current loss value: 4033.5718\n",
      "Current loss value: 4255.492\n",
      "Current loss value: 4478.976\n",
      "Filter 28 processed in 1s\n",
      "Processing filter 29\n",
      "Current loss value: 951.2779\n",
      "Current loss value: 1166.621\n",
      "Current loss value: 1369.2651\n",
      "Current loss value: 1537.1049\n",
      "Current loss value: 1646.0948\n",
      "Current loss value: 1749.5168\n",
      "Current loss value: 1836.0266\n",
      "Current loss value: 1917.297\n",
      "Current loss value: 1997.6328\n",
      "Current loss value: 2077.8594\n",
      "Current loss value: 2154.992\n",
      "Current loss value: 2231.9546\n",
      "Current loss value: 2307.4106\n",
      "Current loss value: 2387.0657\n",
      "Current loss value: 2464.4824\n",
      "Current loss value: 2539.923\n",
      "Current loss value: 2614.3667\n",
      "Current loss value: 2687.1807\n",
      "Current loss value: 2759.421\n",
      "Current loss value: 2831.2544\n",
      "Filter 29 processed in 0s\n",
      "Processing filter 30\n",
      "Current loss value: 0.0\n",
      "Filter 30 processed in 0s\n",
      "Processing filter 31\n",
      "Current loss value: 0.0\n",
      "Filter 31 processed in 0s\n",
      "Processing filter 32\n",
      "Current loss value: 125.763145\n",
      "Current loss value: 203.5092\n",
      "Current loss value: 282.4314\n",
      "Current loss value: 344.4812\n",
      "Current loss value: 394.07666\n",
      "Current loss value: 441.64865\n",
      "Current loss value: 488.1319\n",
      "Current loss value: 526.4989\n",
      "Current loss value: 557.7844\n",
      "Current loss value: 590.7625\n",
      "Current loss value: 624.6765\n",
      "Current loss value: 656.48883\n",
      "Current loss value: 689.87976\n",
      "Current loss value: 721.6536\n",
      "Current loss value: 754.20215\n",
      "Current loss value: 787.3705\n",
      "Current loss value: 820.6408\n",
      "Current loss value: 853.83856\n",
      "Current loss value: 886.4647\n",
      "Current loss value: 919.4499\n",
      "Filter 32 processed in 0s\n",
      "Processing filter 33\n",
      "Current loss value: 2.6807659\n",
      "Current loss value: 9.6387415\n",
      "Current loss value: 20.617176\n",
      "Current loss value: 31.035032\n",
      "Current loss value: 42.221165\n",
      "Current loss value: 56.937263\n",
      "Current loss value: 71.50087\n",
      "Current loss value: 88.080154\n",
      "Current loss value: 106.038994\n",
      "Current loss value: 127.6013\n",
      "Current loss value: 148.0396\n",
      "Current loss value: 168.49536\n",
      "Current loss value: 189.78246\n",
      "Current loss value: 210.52693\n",
      "Current loss value: 234.69601\n",
      "Current loss value: 261.11447\n",
      "Current loss value: 286.9932\n",
      "Current loss value: 313.2988\n",
      "Current loss value: 343.8874\n",
      "Current loss value: 392.37424\n",
      "Filter 33 processed in 1s\n",
      "Processing filter 34\n",
      "Current loss value: 212.57756\n",
      "Current loss value: 253.76636\n",
      "Current loss value: 302.49222\n",
      "Current loss value: 356.6831\n",
      "Current loss value: 410.39407\n",
      "Current loss value: 463.0459\n",
      "Current loss value: 515.99115\n",
      "Current loss value: 566.8048\n",
      "Current loss value: 619.94495\n",
      "Current loss value: 673.0664\n",
      "Current loss value: 726.10474\n",
      "Current loss value: 779.9048\n",
      "Current loss value: 835.6432\n",
      "Current loss value: 890.9597\n",
      "Current loss value: 946.65375\n",
      "Current loss value: 1002.96985\n",
      "Current loss value: 1059.8208\n",
      "Current loss value: 1117.2067\n",
      "Current loss value: 1177.3694\n",
      "Current loss value: 1238.9116\n",
      "Filter 34 processed in 1s\n",
      "Processing filter 35\n",
      "Current loss value: 6084.4917\n",
      "Current loss value: 6419.2764\n",
      "Current loss value: 6770.8984\n",
      "Current loss value: 7133.898\n",
      "Current loss value: 7511.1675\n",
      "Current loss value: 7889.631\n",
      "Current loss value: 8265.865\n",
      "Current loss value: 8638.725\n",
      "Current loss value: 9009.695\n",
      "Current loss value: 9380.945\n",
      "Current loss value: 9753.672\n",
      "Current loss value: 10129.398\n",
      "Current loss value: 10504.136\n",
      "Current loss value: 10875.814\n",
      "Current loss value: 11246.602\n",
      "Current loss value: 11618.902\n",
      "Current loss value: 11989.779\n",
      "Current loss value: 12363.648\n",
      "Current loss value: 12736.6875\n",
      "Current loss value: 13111.996\n",
      "Filter 35 processed in 1s\n",
      "Processing filter 36\n",
      "Current loss value: 7490.139\n",
      "Current loss value: 8052.088\n",
      "Current loss value: 8626.457\n",
      "Current loss value: 9199.985\n",
      "Current loss value: 9782.782\n",
      "Current loss value: 10368.511\n",
      "Current loss value: 10947.878\n",
      "Current loss value: 11521.183\n",
      "Current loss value: 12084.177\n",
      "Current loss value: 12641.439\n",
      "Current loss value: 13196.223\n",
      "Current loss value: 13746.811\n",
      "Current loss value: 14293.151\n",
      "Current loss value: 14841.342\n",
      "Current loss value: 15388.685\n",
      "Current loss value: 15932.6875\n",
      "Current loss value: 16475.195\n",
      "Current loss value: 17013.82\n",
      "Current loss value: 17557.902\n",
      "Current loss value: 18096.61\n",
      "Filter 36 processed in 0s\n",
      "Processing filter 37\n",
      "Current loss value: 6764.1094\n",
      "Current loss value: 7564.0977\n",
      "Current loss value: 8365.3545\n",
      "Current loss value: 9198.502\n",
      "Current loss value: 10048.666\n",
      "Current loss value: 10910.35\n",
      "Current loss value: 11781.668\n",
      "Current loss value: 12665.788\n",
      "Current loss value: 13559.984\n",
      "Current loss value: 14452.569\n",
      "Current loss value: 15342.029\n",
      "Current loss value: 16236.133\n",
      "Current loss value: 17132.0\n",
      "Current loss value: 18027.598\n",
      "Current loss value: 18926.125\n",
      "Current loss value: 19832.494\n",
      "Current loss value: 20734.316\n",
      "Current loss value: 21637.23\n",
      "Current loss value: 22540.41\n",
      "Current loss value: 23442.143\n",
      "Filter 37 processed in 1s\n",
      "Processing filter 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 3790.5454\n",
      "Current loss value: 3920.066\n",
      "Current loss value: 4045.8403\n",
      "Current loss value: 4163.8945\n",
      "Current loss value: 4276.7534\n",
      "Current loss value: 4387.6265\n",
      "Current loss value: 4496.8667\n",
      "Current loss value: 4606.977\n",
      "Current loss value: 4709.9077\n",
      "Current loss value: 4813.45\n",
      "Current loss value: 4916.0293\n",
      "Current loss value: 5014.9277\n",
      "Current loss value: 5113.257\n",
      "Current loss value: 5210.2686\n",
      "Current loss value: 5308.8013\n",
      "Current loss value: 5410.5723\n",
      "Current loss value: 5510.469\n",
      "Current loss value: 5608.709\n",
      "Current loss value: 5713.4478\n",
      "Current loss value: 5825.1035\n",
      "Filter 38 processed in 1s\n",
      "Processing filter 39\n",
      "Current loss value: 7869.0127\n",
      "Current loss value: 8710.133\n",
      "Current loss value: 9563.011\n",
      "Current loss value: 10443.816\n",
      "Current loss value: 11335.158\n",
      "Current loss value: 12221.709\n",
      "Current loss value: 13110.996\n",
      "Current loss value: 13999.45\n",
      "Current loss value: 14885.011\n",
      "Current loss value: 15778.559\n",
      "Current loss value: 16668.93\n",
      "Current loss value: 17562.762\n",
      "Current loss value: 18464.879\n",
      "Current loss value: 19369.7\n",
      "Current loss value: 20271.396\n",
      "Current loss value: 21172.75\n",
      "Current loss value: 22076.262\n",
      "Current loss value: 22981.24\n",
      "Current loss value: 23885.564\n",
      "Current loss value: 24794.174\n",
      "Filter 39 processed in 1s\n",
      "Processing filter 40\n",
      "Current loss value: 0.0\n",
      "Filter 40 processed in 0s\n",
      "Processing filter 41\n",
      "Current loss value: 0.0\n",
      "Filter 41 processed in 0s\n",
      "Processing filter 42\n",
      "Current loss value: 18423.277\n",
      "Current loss value: 19903.432\n",
      "Current loss value: 21408.547\n",
      "Current loss value: 22947.906\n",
      "Current loss value: 24526.719\n",
      "Current loss value: 26116.453\n",
      "Current loss value: 27721.375\n",
      "Current loss value: 29336.934\n",
      "Current loss value: 30949.23\n",
      "Current loss value: 32541.266\n",
      "Current loss value: 34132.227\n",
      "Current loss value: 35720.85\n",
      "Current loss value: 37306.598\n",
      "Current loss value: 38906.953\n",
      "Current loss value: 40507.82\n",
      "Current loss value: 42121.57\n",
      "Current loss value: 43738.047\n",
      "Current loss value: 45357.598\n",
      "Current loss value: 46970.15\n",
      "Current loss value: 48583.977\n",
      "Filter 42 processed in 1s\n",
      "Processing filter 43\n",
      "Current loss value: 284.79388\n",
      "Current loss value: 375.76636\n",
      "Current loss value: 474.02512\n",
      "Current loss value: 580.62256\n",
      "Current loss value: 695.32446\n",
      "Current loss value: 811.1339\n",
      "Current loss value: 932.1819\n",
      "Current loss value: 1064.3577\n",
      "Current loss value: 1205.4355\n",
      "Current loss value: 1357.0225\n",
      "Current loss value: 1519.6753\n",
      "Current loss value: 1687.9377\n",
      "Current loss value: 1862.5876\n",
      "Current loss value: 2043.9248\n",
      "Current loss value: 2233.238\n",
      "Current loss value: 2429.451\n",
      "Current loss value: 2629.2686\n",
      "Current loss value: 2833.5554\n",
      "Current loss value: 3050.4656\n",
      "Current loss value: 3272.813\n",
      "Filter 43 processed in 1s\n",
      "Processing filter 44\n",
      "Current loss value: 10252.612\n",
      "Current loss value: 11050.295\n",
      "Current loss value: 11845.263\n",
      "Current loss value: 12637.768\n",
      "Current loss value: 13453.169\n",
      "Current loss value: 14270.58\n",
      "Current loss value: 15080.893\n",
      "Current loss value: 15874.099\n",
      "Current loss value: 16659.826\n",
      "Current loss value: 17431.469\n",
      "Current loss value: 18204.117\n",
      "Current loss value: 18971.66\n",
      "Current loss value: 19740.371\n",
      "Current loss value: 20499.969\n",
      "Current loss value: 21257.904\n",
      "Current loss value: 22011.855\n",
      "Current loss value: 22766.363\n",
      "Current loss value: 23518.809\n",
      "Current loss value: 24273.242\n",
      "Current loss value: 25026.113\n",
      "Filter 44 processed in 1s\n",
      "Processing filter 45\n",
      "Current loss value: 107.19958\n",
      "Current loss value: 133.19984\n",
      "Current loss value: 157.60501\n",
      "Current loss value: 179.77875\n",
      "Current loss value: 201.39018\n",
      "Current loss value: 221.33972\n",
      "Current loss value: 239.84323\n",
      "Current loss value: 258.7205\n",
      "Current loss value: 277.4196\n",
      "Current loss value: 295.48297\n",
      "Current loss value: 313.6605\n",
      "Current loss value: 331.97693\n",
      "Current loss value: 351.3938\n",
      "Current loss value: 371.4306\n",
      "Current loss value: 391.50528\n",
      "Current loss value: 410.99902\n",
      "Current loss value: 430.7336\n",
      "Current loss value: 449.48178\n",
      "Current loss value: 473.758\n",
      "Current loss value: 501.10196\n",
      "Filter 45 processed in 1s\n",
      "Processing filter 46\n",
      "Current loss value: 1798.3619\n",
      "Current loss value: 1882.7748\n",
      "Current loss value: 1972.3679\n",
      "Current loss value: 2053.6492\n",
      "Current loss value: 2128.2554\n",
      "Current loss value: 2205.3635\n",
      "Current loss value: 2276.456\n",
      "Current loss value: 2345.0305\n",
      "Current loss value: 2415.1514\n",
      "Current loss value: 2488.101\n",
      "Current loss value: 2559.9863\n",
      "Current loss value: 2635.5044\n",
      "Current loss value: 2706.355\n",
      "Current loss value: 2769.8599\n",
      "Current loss value: 2834.502\n",
      "Current loss value: 2899.9592\n",
      "Current loss value: 2965.7617\n",
      "Current loss value: 3031.895\n",
      "Current loss value: 3097.5056\n",
      "Current loss value: 3163.0137\n",
      "Filter 46 processed in 1s\n",
      "Processing filter 47\n",
      "Current loss value: 1538.9578\n",
      "Current loss value: 1754.8877\n",
      "Current loss value: 1966.5916\n",
      "Current loss value: 2178.6558\n",
      "Current loss value: 2397.0503\n",
      "Current loss value: 2611.4153\n",
      "Current loss value: 2819.5312\n",
      "Current loss value: 3023.845\n",
      "Current loss value: 3221.0784\n",
      "Current loss value: 3418.1594\n",
      "Current loss value: 3611.758\n",
      "Current loss value: 3804.675\n",
      "Current loss value: 3996.2085\n",
      "Current loss value: 4187.511\n",
      "Current loss value: 4378.5156\n",
      "Current loss value: 4569.2803\n",
      "Current loss value: 4758.7114\n",
      "Current loss value: 4946.4067\n",
      "Current loss value: 5134.4854\n",
      "Current loss value: 5321.576\n",
      "Filter 47 processed in 1s\n",
      "Processing filter 48\n",
      "Current loss value: 14598.289\n",
      "Current loss value: 15535.75\n",
      "Current loss value: 16500.559\n",
      "Current loss value: 17486.6\n",
      "Current loss value: 18496.164\n",
      "Current loss value: 19509.402\n",
      "Current loss value: 20520.414\n",
      "Current loss value: 21529.883\n",
      "Current loss value: 22534.223\n",
      "Current loss value: 23531.164\n",
      "Current loss value: 24530.072\n",
      "Current loss value: 25527.303\n",
      "Current loss value: 26520.059\n",
      "Current loss value: 27511.133\n",
      "Current loss value: 28507.504\n",
      "Current loss value: 29502.312\n",
      "Current loss value: 30498.637\n",
      "Current loss value: 31500.168\n",
      "Current loss value: 32508.363\n",
      "Current loss value: 33516.86\n",
      "Filter 48 processed in 1s\n",
      "Processing filter 49\n",
      "Current loss value: 7666.967\n",
      "Current loss value: 8175.457\n",
      "Current loss value: 8708.386\n",
      "Current loss value: 9275.029\n",
      "Current loss value: 9872.066\n",
      "Current loss value: 10474.762\n",
      "Current loss value: 11081.653\n",
      "Current loss value: 11693.664\n",
      "Current loss value: 12317.75\n",
      "Current loss value: 12945.483\n",
      "Current loss value: 13578.051\n",
      "Current loss value: 14212.041\n",
      "Current loss value: 14847.15\n",
      "Current loss value: 15484.545\n",
      "Current loss value: 16122.073\n",
      "Current loss value: 16767.12\n",
      "Current loss value: 17417.547\n",
      "Current loss value: 18068.215\n",
      "Current loss value: 18720.996\n",
      "Current loss value: 19374.816\n",
      "Filter 49 processed in 1s\n",
      "Processing filter 50\n",
      "Current loss value: 58.372368\n",
      "Current loss value: 103.39488\n",
      "Current loss value: 168.53633\n",
      "Current loss value: 253.64893\n",
      "Current loss value: 358.74402\n",
      "Current loss value: 480.9442\n",
      "Current loss value: 610.43616\n",
      "Current loss value: 745.45935\n",
      "Current loss value: 890.7881\n",
      "Current loss value: 1040.804\n",
      "Current loss value: 1201.8938\n",
      "Current loss value: 1369.5264\n",
      "Current loss value: 1548.032\n",
      "Current loss value: 1746.8907\n",
      "Current loss value: 1954.4084\n",
      "Current loss value: 2169.3064\n",
      "Current loss value: 2391.3994\n",
      "Current loss value: 2625.4329\n",
      "Current loss value: 2865.0405\n",
      "Current loss value: 3110.014\n",
      "Filter 50 processed in 1s\n",
      "Processing filter 51\n",
      "Current loss value: 12083.668\n",
      "Current loss value: 12748.303\n",
      "Current loss value: 13418.99\n",
      "Current loss value: 14086.084\n",
      "Current loss value: 14758.027\n",
      "Current loss value: 15428.408\n",
      "Current loss value: 16087.477\n",
      "Current loss value: 16739.047\n",
      "Current loss value: 17375.902\n",
      "Current loss value: 18010.023\n",
      "Current loss value: 18637.586\n",
      "Current loss value: 19266.39\n",
      "Current loss value: 19893.742\n",
      "Current loss value: 20517.027\n",
      "Current loss value: 21136.07\n",
      "Current loss value: 21752.492\n",
      "Current loss value: 22362.508\n",
      "Current loss value: 22969.691\n",
      "Current loss value: 23574.727\n",
      "Current loss value: 24180.73\n",
      "Filter 51 processed in 1s\n",
      "Processing filter 52\n",
      "Current loss value: 0.0\n",
      "Filter 52 processed in 1s\n",
      "Processing filter 53\n",
      "Current loss value: 995.4798\n",
      "Current loss value: 1232.3988\n",
      "Current loss value: 1469.2019\n",
      "Current loss value: 1713.3345\n",
      "Current loss value: 1958.733\n",
      "Current loss value: 2200.637\n",
      "Current loss value: 2441.746\n",
      "Current loss value: 2686.076\n",
      "Current loss value: 2927.0469\n",
      "Current loss value: 3165.917\n",
      "Current loss value: 3402.457\n",
      "Current loss value: 3637.7935\n",
      "Current loss value: 3871.9785\n",
      "Current loss value: 4106.857\n",
      "Current loss value: 4344.5093\n",
      "Current loss value: 4583.2803\n",
      "Current loss value: 4824.245\n",
      "Current loss value: 5065.532\n",
      "Current loss value: 5308.843\n",
      "Current loss value: 5554.3633\n",
      "Filter 53 processed in 1s\n",
      "Processing filter 54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 8970.265\n",
      "Current loss value: 9507.836\n",
      "Current loss value: 10079.196\n",
      "Current loss value: 10698.381\n",
      "Current loss value: 11348.449\n",
      "Current loss value: 12007.003\n",
      "Current loss value: 12672.375\n",
      "Current loss value: 13348.104\n",
      "Current loss value: 14025.854\n",
      "Current loss value: 14701.122\n",
      "Current loss value: 15379.218\n",
      "Current loss value: 16064.463\n",
      "Current loss value: 16753.5\n",
      "Current loss value: 17443.754\n",
      "Current loss value: 18139.791\n",
      "Current loss value: 18841.877\n",
      "Current loss value: 19543.451\n",
      "Current loss value: 20242.129\n",
      "Current loss value: 20944.266\n",
      "Current loss value: 21652.098\n",
      "Filter 54 processed in 1s\n",
      "Processing filter 55\n",
      "Current loss value: 8767.546\n",
      "Current loss value: 9498.687\n",
      "Current loss value: 10242.314\n",
      "Current loss value: 11002.621\n",
      "Current loss value: 11777.827\n",
      "Current loss value: 12562.887\n",
      "Current loss value: 13349.322\n",
      "Current loss value: 14125.115\n",
      "Current loss value: 14895.599\n",
      "Current loss value: 15669.209\n",
      "Current loss value: 16432.256\n",
      "Current loss value: 17197.418\n",
      "Current loss value: 17958.219\n",
      "Current loss value: 18724.367\n",
      "Current loss value: 19489.04\n",
      "Current loss value: 20259.26\n",
      "Current loss value: 21026.086\n",
      "Current loss value: 21790.678\n",
      "Current loss value: 22553.883\n",
      "Current loss value: 23320.537\n",
      "Filter 55 processed in 1s\n",
      "Processing filter 56\n",
      "Current loss value: 15246.482\n",
      "Current loss value: 16290.898\n",
      "Current loss value: 17385.371\n",
      "Current loss value: 18531.441\n",
      "Current loss value: 19702.984\n",
      "Current loss value: 20872.375\n",
      "Current loss value: 22039.385\n",
      "Current loss value: 23206.863\n",
      "Current loss value: 24372.54\n",
      "Current loss value: 25544.166\n",
      "Current loss value: 26715.219\n",
      "Current loss value: 27891.883\n",
      "Current loss value: 29074.14\n",
      "Current loss value: 30253.098\n",
      "Current loss value: 31431.516\n",
      "Current loss value: 32609.766\n",
      "Current loss value: 33791.406\n",
      "Current loss value: 34965.668\n",
      "Current loss value: 36143.438\n",
      "Current loss value: 37321.938\n",
      "Filter 56 processed in 1s\n",
      "Processing filter 57\n",
      "Current loss value: 0.0\n",
      "Filter 57 processed in 1s\n",
      "Processing filter 58\n",
      "Current loss value: 1304.6354\n",
      "Current loss value: 1426.4915\n",
      "Current loss value: 1553.6919\n",
      "Current loss value: 1678.2146\n",
      "Current loss value: 1803.916\n",
      "Current loss value: 1927.845\n",
      "Current loss value: 2046.6825\n",
      "Current loss value: 2163.265\n",
      "Current loss value: 2279.9207\n",
      "Current loss value: 2396.9502\n",
      "Current loss value: 2512.8794\n",
      "Current loss value: 2626.5193\n",
      "Current loss value: 2738.8923\n",
      "Current loss value: 2851.3306\n",
      "Current loss value: 2963.1226\n",
      "Current loss value: 3073.316\n",
      "Current loss value: 3184.836\n",
      "Current loss value: 3295.8972\n",
      "Current loss value: 3407.687\n",
      "Current loss value: 3519.4338\n",
      "Filter 58 processed in 1s\n",
      "Processing filter 59\n",
      "Current loss value: 81.58327\n",
      "Current loss value: 92.16626\n",
      "Current loss value: 110.80478\n",
      "Current loss value: 128.96567\n",
      "Current loss value: 147.54857\n",
      "Current loss value: 166.96716\n",
      "Current loss value: 184.10632\n",
      "Current loss value: 202.06558\n",
      "Current loss value: 221.48279\n",
      "Current loss value: 240.6193\n",
      "Current loss value: 259.6977\n",
      "Current loss value: 278.52188\n",
      "Current loss value: 298.4797\n",
      "Current loss value: 319.64102\n",
      "Current loss value: 341.5094\n",
      "Current loss value: 363.38098\n",
      "Current loss value: 386.23956\n",
      "Current loss value: 415.5235\n",
      "Current loss value: 449.2679\n",
      "Current loss value: 482.088\n",
      "Filter 59 processed in 1s\n",
      "Processing filter 60\n",
      "Current loss value: 0.0\n",
      "Filter 60 processed in 1s\n",
      "Processing filter 61\n",
      "Current loss value: 4542.663\n",
      "Current loss value: 4701.823\n",
      "Current loss value: 4873.9336\n",
      "Current loss value: 5045.34\n",
      "Current loss value: 5213.1157\n",
      "Current loss value: 5385.2754\n",
      "Current loss value: 5560.0024\n",
      "Current loss value: 5734.6797\n",
      "Current loss value: 5910.077\n",
      "Current loss value: 6083.2373\n",
      "Current loss value: 6254.2793\n",
      "Current loss value: 6424.2783\n",
      "Current loss value: 6594.316\n",
      "Current loss value: 6763.525\n",
      "Current loss value: 6932.08\n",
      "Current loss value: 7098.6104\n",
      "Current loss value: 7262.4316\n",
      "Current loss value: 7425.6836\n",
      "Current loss value: 7587.09\n",
      "Current loss value: 7748.426\n",
      "Filter 61 processed in 1s\n",
      "Processing filter 62\n",
      "Current loss value: 0.0\n",
      "Filter 62 processed in 1s\n",
      "Processing filter 63\n",
      "Current loss value: 4868.6914\n",
      "Current loss value: 5488.6426\n",
      "Current loss value: 6121.7715\n",
      "Current loss value: 6789.303\n",
      "Current loss value: 7472.397\n",
      "Current loss value: 8152.297\n",
      "Current loss value: 8837.768\n",
      "Current loss value: 9540.81\n",
      "Current loss value: 10245.814\n",
      "Current loss value: 10957.614\n",
      "Current loss value: 11669.303\n",
      "Current loss value: 12380.816\n",
      "Current loss value: 13091.03\n",
      "Current loss value: 13805.958\n",
      "Current loss value: 14523.83\n",
      "Current loss value: 15240.8125\n",
      "Current loss value: 15961.879\n",
      "Current loss value: 16682.84\n",
      "Current loss value: 17406.107\n",
      "Current loss value: 18129.809\n",
      "Filter 63 processed in 1s\n",
      "Processing filter 64\n",
      "Current loss value: 2017.5913\n",
      "Current loss value: 2096.692\n",
      "Current loss value: 2179.907\n",
      "Current loss value: 2256.51\n",
      "Current loss value: 2333.022\n",
      "Current loss value: 2404.7368\n",
      "Current loss value: 2474.6548\n",
      "Current loss value: 2544.169\n",
      "Current loss value: 2614.0073\n",
      "Current loss value: 2680.9204\n",
      "Current loss value: 2750.1064\n",
      "Current loss value: 2818.6104\n",
      "Current loss value: 2883.4248\n",
      "Current loss value: 2955.1953\n",
      "Current loss value: 3026.6982\n",
      "Current loss value: 3095.996\n",
      "Current loss value: 3165.6343\n",
      "Current loss value: 3239.5242\n",
      "Current loss value: 3312.673\n",
      "Current loss value: 3385.0435\n",
      "Filter 64 processed in 1s\n",
      "Processing filter 65\n",
      "Current loss value: 7014.075\n",
      "Current loss value: 7493.532\n",
      "Current loss value: 7986.7344\n",
      "Current loss value: 8482.579\n",
      "Current loss value: 8983.274\n",
      "Current loss value: 9483.123\n",
      "Current loss value: 9976.972\n",
      "Current loss value: 10457.277\n",
      "Current loss value: 10932.375\n",
      "Current loss value: 11399.91\n",
      "Current loss value: 11865.227\n",
      "Current loss value: 12328.137\n",
      "Current loss value: 12788.709\n",
      "Current loss value: 13246.07\n",
      "Current loss value: 13701.416\n",
      "Current loss value: 14153.075\n",
      "Current loss value: 14599.013\n",
      "Current loss value: 15045.088\n",
      "Current loss value: 15489.679\n",
      "Current loss value: 15936.303\n",
      "Filter 65 processed in 1s\n",
      "Processing filter 66\n",
      "Current loss value: 7586.1714\n",
      "Current loss value: 8028.296\n",
      "Current loss value: 8507.372\n",
      "Current loss value: 9021.729\n",
      "Current loss value: 9562.555\n",
      "Current loss value: 10100.293\n",
      "Current loss value: 10641.4375\n",
      "Current loss value: 11195.526\n",
      "Current loss value: 11758.855\n",
      "Current loss value: 12321.6\n",
      "Current loss value: 12889.137\n",
      "Current loss value: 13466.293\n",
      "Current loss value: 14046.492\n",
      "Current loss value: 14625.59\n",
      "Current loss value: 15208.5205\n",
      "Current loss value: 15791.887\n",
      "Current loss value: 16379.002\n",
      "Current loss value: 16972.357\n",
      "Current loss value: 17571.059\n",
      "Current loss value: 18169.07\n",
      "Filter 66 processed in 1s\n",
      "Processing filter 67\n",
      "Current loss value: 0.0\n",
      "Filter 67 processed in 1s\n",
      "Processing filter 68\n",
      "Current loss value: 0.0\n",
      "Filter 68 processed in 1s\n",
      "Processing filter 69\n",
      "Current loss value: 3439.5613\n",
      "Current loss value: 4045.4\n",
      "Current loss value: 4647.1455\n",
      "Current loss value: 5284.699\n",
      "Current loss value: 5934.036\n",
      "Current loss value: 6585.1533\n",
      "Current loss value: 7245.0317\n",
      "Current loss value: 7926.742\n",
      "Current loss value: 8613.117\n",
      "Current loss value: 9311.392\n",
      "Current loss value: 10008.473\n",
      "Current loss value: 10707.266\n",
      "Current loss value: 11403.98\n",
      "Current loss value: 12102.354\n",
      "Current loss value: 12801.205\n",
      "Current loss value: 13507.633\n",
      "Current loss value: 14210.305\n",
      "Current loss value: 14917.147\n",
      "Current loss value: 15628.633\n",
      "Current loss value: 16345.524\n",
      "Filter 69 processed in 1s\n",
      "Processing filter 70\n",
      "Current loss value: 0.0\n",
      "Filter 70 processed in 1s\n",
      "Processing filter 71\n",
      "Current loss value: 10829.717\n",
      "Current loss value: 11661.479\n",
      "Current loss value: 12500.527\n",
      "Current loss value: 13347.363\n",
      "Current loss value: 14214.859\n",
      "Current loss value: 15081.364\n",
      "Current loss value: 15944.986\n",
      "Current loss value: 16798.975\n",
      "Current loss value: 17642.64\n",
      "Current loss value: 18473.803\n",
      "Current loss value: 19298.88\n",
      "Current loss value: 20125.527\n",
      "Current loss value: 20953.656\n",
      "Current loss value: 21778.643\n",
      "Current loss value: 22601.129\n",
      "Current loss value: 23422.871\n",
      "Current loss value: 24245.184\n",
      "Current loss value: 25062.11\n",
      "Current loss value: 25879.926\n",
      "Current loss value: 26693.738\n",
      "Filter 71 processed in 1s\n",
      "Processing filter 72\n",
      "Current loss value: 321.7959\n",
      "Current loss value: 402.56763\n",
      "Current loss value: 485.21918\n",
      "Current loss value: 564.74\n",
      "Current loss value: 650.8153\n",
      "Current loss value: 739.86884\n",
      "Current loss value: 830.8528\n",
      "Current loss value: 924.60236\n",
      "Current loss value: 1025.694\n",
      "Current loss value: 1130.0726\n",
      "Current loss value: 1234.3936\n",
      "Current loss value: 1340.0417\n",
      "Current loss value: 1446.3191\n",
      "Current loss value: 1556.8341\n",
      "Current loss value: 1669.575\n",
      "Current loss value: 1787.2349\n",
      "Current loss value: 1910.6696\n",
      "Current loss value: 2037.7955\n",
      "Current loss value: 2168.5667\n",
      "Current loss value: 2301.4587\n",
      "Filter 72 processed in 1s\n",
      "Processing filter 73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 0.0\n",
      "Filter 73 processed in 1s\n",
      "Processing filter 74\n",
      "Current loss value: 5724.3877\n",
      "Current loss value: 6188.425\n",
      "Current loss value: 6658.864\n",
      "Current loss value: 7142.9375\n",
      "Current loss value: 7639.984\n",
      "Current loss value: 8142.465\n",
      "Current loss value: 8641.252\n",
      "Current loss value: 9148.355\n",
      "Current loss value: 9649.613\n",
      "Current loss value: 10146.643\n",
      "Current loss value: 10640.21\n",
      "Current loss value: 11129.32\n",
      "Current loss value: 11616.672\n",
      "Current loss value: 12103.21\n",
      "Current loss value: 12586.942\n",
      "Current loss value: 13070.813\n",
      "Current loss value: 13553.232\n",
      "Current loss value: 14035.614\n",
      "Current loss value: 14522.293\n",
      "Current loss value: 15008.355\n",
      "Filter 74 processed in 1s\n",
      "Processing filter 75\n",
      "Current loss value: 0.0\n",
      "Filter 75 processed in 1s\n",
      "Processing filter 76\n",
      "Current loss value: 0.0\n",
      "Filter 76 processed in 1s\n",
      "Processing filter 77\n",
      "Current loss value: 635.7956\n",
      "Current loss value: 734.8\n",
      "Current loss value: 826.04004\n",
      "Current loss value: 902.6605\n",
      "Current loss value: 988.75323\n",
      "Current loss value: 1079.7019\n",
      "Current loss value: 1170.1593\n",
      "Current loss value: 1263.1409\n",
      "Current loss value: 1358.4446\n",
      "Current loss value: 1456.0162\n",
      "Current loss value: 1552.9072\n",
      "Current loss value: 1654.1273\n",
      "Current loss value: 1753.643\n",
      "Current loss value: 1857.5496\n",
      "Current loss value: 1962.1279\n",
      "Current loss value: 2071.221\n",
      "Current loss value: 2185.4543\n",
      "Current loss value: 2301.294\n",
      "Current loss value: 2419.7986\n",
      "Current loss value: 2540.8232\n",
      "Filter 77 processed in 1s\n",
      "Processing filter 78\n",
      "Current loss value: 1391.8715\n",
      "Current loss value: 1587.3005\n",
      "Current loss value: 1767.2249\n",
      "Current loss value: 1904.4673\n",
      "Current loss value: 2036.2325\n",
      "Current loss value: 2172.1274\n",
      "Current loss value: 2315.5889\n",
      "Current loss value: 2458.6614\n",
      "Current loss value: 2585.7\n",
      "Current loss value: 2704.4275\n",
      "Current loss value: 2818.4468\n",
      "Current loss value: 2924.9778\n",
      "Current loss value: 3028.162\n",
      "Current loss value: 3128.986\n",
      "Current loss value: 3227.97\n",
      "Current loss value: 3327.289\n",
      "Current loss value: 3425.5093\n",
      "Current loss value: 3521.9727\n",
      "Current loss value: 3617.831\n",
      "Current loss value: 3711.564\n",
      "Filter 78 processed in 1s\n",
      "Processing filter 79\n",
      "Current loss value: 8307.46\n",
      "Current loss value: 8764.83\n",
      "Current loss value: 9236.9375\n",
      "Current loss value: 9714.85\n",
      "Current loss value: 10210.76\n",
      "Current loss value: 10709.277\n",
      "Current loss value: 11206.805\n",
      "Current loss value: 11697.992\n",
      "Current loss value: 12182.912\n",
      "Current loss value: 12668.488\n",
      "Current loss value: 13153.145\n",
      "Current loss value: 13641.604\n",
      "Current loss value: 14129.055\n",
      "Current loss value: 14615.227\n",
      "Current loss value: 15097.6875\n",
      "Current loss value: 15579.416\n",
      "Current loss value: 16057.542\n",
      "Current loss value: 16536.332\n",
      "Current loss value: 17012.52\n",
      "Current loss value: 17490.691\n",
      "Filter 79 processed in 1s\n",
      "Processing filter 80\n",
      "Current loss value: 10788.639\n",
      "Current loss value: 11677.666\n",
      "Current loss value: 12583.48\n",
      "Current loss value: 13526.818\n",
      "Current loss value: 14500.152\n",
      "Current loss value: 15467.494\n",
      "Current loss value: 16431.4\n",
      "Current loss value: 17410.305\n",
      "Current loss value: 18402.336\n",
      "Current loss value: 19394.04\n",
      "Current loss value: 20382.133\n",
      "Current loss value: 21377.688\n",
      "Current loss value: 22372.434\n",
      "Current loss value: 23371.459\n",
      "Current loss value: 24372.121\n",
      "Current loss value: 25371.0\n",
      "Current loss value: 26370.547\n",
      "Current loss value: 27370.504\n",
      "Current loss value: 28374.387\n",
      "Current loss value: 29385.174\n",
      "Filter 80 processed in 1s\n",
      "Processing filter 81\n",
      "Current loss value: 0.0\n",
      "Filter 81 processed in 1s\n",
      "Processing filter 82\n",
      "Current loss value: 0.0\n",
      "Filter 82 processed in 1s\n",
      "Processing filter 83\n",
      "Current loss value: 0.0\n",
      "Filter 83 processed in 1s\n",
      "Processing filter 84\n",
      "Current loss value: 7470.172\n",
      "Current loss value: 8125.036\n",
      "Current loss value: 8790.008\n",
      "Current loss value: 9485.898\n",
      "Current loss value: 10202.696\n",
      "Current loss value: 10921.389\n",
      "Current loss value: 11651.516\n",
      "Current loss value: 12399.198\n",
      "Current loss value: 13145.31\n",
      "Current loss value: 13888.229\n",
      "Current loss value: 14631.089\n",
      "Current loss value: 15371.904\n",
      "Current loss value: 16110.495\n",
      "Current loss value: 16847.871\n",
      "Current loss value: 17591.734\n",
      "Current loss value: 18340.07\n",
      "Current loss value: 19100.03\n",
      "Current loss value: 19862.979\n",
      "Current loss value: 20633.523\n",
      "Current loss value: 21402.285\n",
      "Filter 84 processed in 1s\n",
      "Processing filter 85\n",
      "Current loss value: 6626.7705\n",
      "Current loss value: 7482.076\n",
      "Current loss value: 8323.793\n",
      "Current loss value: 9156.916\n",
      "Current loss value: 10001.008\n",
      "Current loss value: 10843.942\n",
      "Current loss value: 11669.576\n",
      "Current loss value: 12476.686\n",
      "Current loss value: 13265.639\n",
      "Current loss value: 14048.6045\n",
      "Current loss value: 14825.255\n",
      "Current loss value: 15601.471\n",
      "Current loss value: 16371.133\n",
      "Current loss value: 17128.77\n",
      "Current loss value: 17881.527\n",
      "Current loss value: 18630.977\n",
      "Current loss value: 19379.738\n",
      "Current loss value: 20127.438\n",
      "Current loss value: 20870.188\n",
      "Current loss value: 21610.375\n",
      "Filter 85 processed in 1s\n",
      "Processing filter 86\n",
      "Current loss value: 12663.842\n",
      "Current loss value: 13850.432\n",
      "Current loss value: 15027.171\n",
      "Current loss value: 16221.678\n",
      "Current loss value: 17434.285\n",
      "Current loss value: 18639.613\n",
      "Current loss value: 19846.934\n",
      "Current loss value: 21067.027\n",
      "Current loss value: 22275.615\n",
      "Current loss value: 23478.52\n",
      "Current loss value: 24675.316\n",
      "Current loss value: 25861.715\n",
      "Current loss value: 27045.14\n",
      "Current loss value: 28229.602\n",
      "Current loss value: 29416.012\n",
      "Current loss value: 30603.043\n",
      "Current loss value: 31782.953\n",
      "Current loss value: 32963.086\n",
      "Current loss value: 34132.32\n",
      "Current loss value: 35297.816\n",
      "Filter 86 processed in 1s\n",
      "Processing filter 87\n",
      "Current loss value: 0.0\n",
      "Filter 87 processed in 1s\n",
      "Processing filter 88\n",
      "Current loss value: 2164.045\n",
      "Current loss value: 2253.087\n",
      "Current loss value: 2342.9746\n",
      "Current loss value: 2429.0596\n",
      "Current loss value: 2517.8076\n",
      "Current loss value: 2608.3975\n",
      "Current loss value: 2698.786\n",
      "Current loss value: 2789.3013\n",
      "Current loss value: 2879.1616\n",
      "Current loss value: 2972.7102\n",
      "Current loss value: 3071.2017\n",
      "Current loss value: 3165.4695\n",
      "Current loss value: 3262.0054\n",
      "Current loss value: 3357.914\n",
      "Current loss value: 3452.2441\n",
      "Current loss value: 3551.4854\n",
      "Current loss value: 3661.9934\n",
      "Current loss value: 3786.9019\n",
      "Current loss value: 3931.6826\n",
      "Current loss value: 4093.7588\n",
      "Filter 88 processed in 1s\n",
      "Processing filter 89\n",
      "Current loss value: 0.0\n",
      "Filter 89 processed in 1s\n",
      "Processing filter 90\n",
      "Current loss value: 0.0\n",
      "Filter 90 processed in 1s\n",
      "Processing filter 91\n",
      "Current loss value: 0.0\n",
      "Filter 91 processed in 1s\n",
      "Processing filter 92\n",
      "Current loss value: 0.0\n",
      "Filter 92 processed in 1s\n",
      "Processing filter 93\n",
      "Current loss value: 0.0\n",
      "Filter 93 processed in 1s\n",
      "Processing filter 94\n",
      "Current loss value: 0.0\n",
      "Filter 94 processed in 1s\n",
      "Processing filter 95\n",
      "Current loss value: 1248.9138\n",
      "Current loss value: 1443.8213\n",
      "Current loss value: 1638.0425\n",
      "Current loss value: 1828.5261\n",
      "Current loss value: 2019.7692\n",
      "Current loss value: 2211.8713\n",
      "Current loss value: 2402.411\n",
      "Current loss value: 2590.075\n",
      "Current loss value: 2775.4272\n",
      "Current loss value: 2964.6187\n",
      "Current loss value: 3153.6257\n",
      "Current loss value: 3340.8281\n",
      "Current loss value: 3527.6777\n",
      "Current loss value: 3714.442\n",
      "Current loss value: 3901.724\n",
      "Current loss value: 4088.738\n",
      "Current loss value: 4279.1157\n",
      "Current loss value: 4467.4287\n",
      "Current loss value: 4655.1455\n",
      "Current loss value: 4845.5747\n",
      "Filter 95 processed in 1s\n",
      "Processing filter 96\n",
      "Current loss value: 3250.6821\n",
      "Current loss value: 3641.7192\n",
      "Current loss value: 4032.9834\n",
      "Current loss value: 4421.4653\n",
      "Current loss value: 4811.5205\n",
      "Current loss value: 5202.137\n",
      "Current loss value: 5587.07\n",
      "Current loss value: 5965.577\n",
      "Current loss value: 6340.766\n",
      "Current loss value: 6714.9883\n",
      "Current loss value: 7083.2344\n",
      "Current loss value: 7450.674\n",
      "Current loss value: 7815.504\n",
      "Current loss value: 8176.086\n",
      "Current loss value: 8535.635\n",
      "Current loss value: 8896.66\n",
      "Current loss value: 9259.992\n",
      "Current loss value: 9621.342\n",
      "Current loss value: 9984.02\n",
      "Current loss value: 10347.357\n",
      "Filter 96 processed in 1s\n",
      "Processing filter 97\n",
      "Current loss value: 0.0\n",
      "Filter 97 processed in 1s\n",
      "Processing filter 98\n",
      "Current loss value: 5743.09\n",
      "Current loss value: 6410.208\n",
      "Current loss value: 7078.6343\n",
      "Current loss value: 7759.6323\n",
      "Current loss value: 8457.541\n",
      "Current loss value: 9161.101\n",
      "Current loss value: 9858.177\n",
      "Current loss value: 10550.084\n",
      "Current loss value: 11236.867\n",
      "Current loss value: 11922.254\n",
      "Current loss value: 12605.339\n",
      "Current loss value: 13288.953\n",
      "Current loss value: 13969.354\n",
      "Current loss value: 14647.784\n",
      "Current loss value: 15330.216\n",
      "Current loss value: 16010.047\n",
      "Current loss value: 16685.55\n",
      "Current loss value: 17362.252\n",
      "Current loss value: 18040.062\n",
      "Current loss value: 18716.318\n",
      "Filter 98 processed in 1s\n",
      "Processing filter 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 0.0\n",
      "Filter 99 processed in 1s\n",
      "Processing filter 100\n",
      "Current loss value: 4473.944\n",
      "Current loss value: 4616.055\n",
      "Current loss value: 4759.4824\n",
      "Current loss value: 4899.1616\n",
      "Current loss value: 5037.336\n",
      "Current loss value: 5168.3887\n",
      "Current loss value: 5299.248\n",
      "Current loss value: 5422.0137\n",
      "Current loss value: 5549.439\n",
      "Current loss value: 5678.659\n",
      "Current loss value: 5808.5156\n",
      "Current loss value: 5936.3735\n",
      "Current loss value: 6062.4077\n",
      "Current loss value: 6191.9126\n",
      "Current loss value: 6320.574\n",
      "Current loss value: 6451.2725\n",
      "Current loss value: 6582.7695\n",
      "Current loss value: 6715.892\n",
      "Current loss value: 6849.0\n",
      "Current loss value: 6981.8154\n",
      "Filter 100 processed in 1s\n",
      "Processing filter 101\n",
      "Current loss value: 6334.996\n",
      "Current loss value: 6802.7\n",
      "Current loss value: 7283.3774\n",
      "Current loss value: 7768.905\n",
      "Current loss value: 8261.383\n",
      "Current loss value: 8752.631\n",
      "Current loss value: 9237.059\n",
      "Current loss value: 9720.511\n",
      "Current loss value: 10201.743\n",
      "Current loss value: 10680.934\n",
      "Current loss value: 11152.34\n",
      "Current loss value: 11618.721\n",
      "Current loss value: 12085.002\n",
      "Current loss value: 12544.067\n",
      "Current loss value: 13005.1045\n",
      "Current loss value: 13470.867\n",
      "Current loss value: 13937.713\n",
      "Current loss value: 14402.883\n",
      "Current loss value: 14874.275\n",
      "Current loss value: 15347.179\n",
      "Filter 101 processed in 1s\n",
      "Processing filter 102\n",
      "Current loss value: 3964.4714\n",
      "Current loss value: 4362.101\n",
      "Current loss value: 4786.3105\n",
      "Current loss value: 5266.042\n",
      "Current loss value: 5793.3047\n",
      "Current loss value: 6337.3877\n",
      "Current loss value: 6904.139\n",
      "Current loss value: 7480.6865\n",
      "Current loss value: 8068.618\n",
      "Current loss value: 8660.543\n",
      "Current loss value: 9266.105\n",
      "Current loss value: 9881.693\n",
      "Current loss value: 10499.783\n",
      "Current loss value: 11125.639\n",
      "Current loss value: 11755.049\n",
      "Current loss value: 12390.051\n",
      "Current loss value: 13035.195\n",
      "Current loss value: 13688.5625\n",
      "Current loss value: 14346.148\n",
      "Current loss value: 15009.774\n",
      "Filter 102 processed in 1s\n",
      "Processing filter 103\n",
      "Current loss value: 0.0\n",
      "Filter 103 processed in 1s\n",
      "Processing filter 104\n",
      "Current loss value: 7178.5186\n",
      "Current loss value: 7758.955\n",
      "Current loss value: 8355.598\n",
      "Current loss value: 8963.828\n",
      "Current loss value: 9587.745\n",
      "Current loss value: 10211.433\n",
      "Current loss value: 10808.406\n",
      "Current loss value: 11395.344\n",
      "Current loss value: 11971.444\n",
      "Current loss value: 12541.777\n",
      "Current loss value: 13102.58\n",
      "Current loss value: 13653.057\n",
      "Current loss value: 14201.416\n",
      "Current loss value: 14744.932\n",
      "Current loss value: 15286.576\n",
      "Current loss value: 15822.253\n",
      "Current loss value: 16356.705\n",
      "Current loss value: 16894.852\n",
      "Current loss value: 17433.854\n",
      "Current loss value: 17974.945\n",
      "Filter 104 processed in 1s\n",
      "Processing filter 105\n",
      "Current loss value: 0.0\n",
      "Filter 105 processed in 1s\n",
      "Processing filter 106\n",
      "Current loss value: 554.093\n",
      "Current loss value: 648.72156\n",
      "Current loss value: 740.1594\n",
      "Current loss value: 827.5775\n",
      "Current loss value: 889.12476\n",
      "Current loss value: 964.3882\n",
      "Current loss value: 1027.1349\n",
      "Current loss value: 1086.545\n",
      "Current loss value: 1139.5974\n",
      "Current loss value: 1184.7472\n",
      "Current loss value: 1233.9636\n",
      "Current loss value: 1280.2872\n",
      "Current loss value: 1327.1707\n",
      "Current loss value: 1372.5398\n",
      "Current loss value: 1420.5773\n",
      "Current loss value: 1470.4519\n",
      "Current loss value: 1522.3059\n",
      "Current loss value: 1575.103\n",
      "Current loss value: 1628.8789\n",
      "Current loss value: 1682.55\n",
      "Filter 106 processed in 1s\n",
      "Processing filter 107\n",
      "Current loss value: 0.0\n",
      "Filter 107 processed in 1s\n",
      "Processing filter 108\n",
      "Current loss value: 0.0\n",
      "Filter 108 processed in 1s\n",
      "Processing filter 109\n",
      "Current loss value: 11394.494\n",
      "Current loss value: 12339.542\n",
      "Current loss value: 13302.197\n",
      "Current loss value: 14290.797\n",
      "Current loss value: 15306.414\n",
      "Current loss value: 16329.264\n",
      "Current loss value: 17354.895\n",
      "Current loss value: 18369.514\n",
      "Current loss value: 19382.176\n",
      "Current loss value: 20392.914\n",
      "Current loss value: 21397.646\n",
      "Current loss value: 22395.521\n",
      "Current loss value: 23395.29\n",
      "Current loss value: 24385.89\n",
      "Current loss value: 25379.273\n",
      "Current loss value: 26375.16\n",
      "Current loss value: 27371.855\n",
      "Current loss value: 28366.771\n",
      "Current loss value: 29366.129\n",
      "Current loss value: 30365.031\n",
      "Filter 109 processed in 1s\n",
      "Processing filter 110\n",
      "Current loss value: 0.0\n",
      "Filter 110 processed in 1s\n",
      "Processing filter 111\n",
      "Current loss value: 0.0\n",
      "Filter 111 processed in 1s\n",
      "Processing filter 112\n",
      "Current loss value: 0.0\n",
      "Filter 112 processed in 1s\n",
      "Processing filter 113\n",
      "Current loss value: 0.0\n",
      "Filter 113 processed in 1s\n",
      "Processing filter 114\n",
      "Current loss value: 6421.5713\n",
      "Current loss value: 7046.9805\n",
      "Current loss value: 7677.0015\n",
      "Current loss value: 8312.676\n",
      "Current loss value: 8950.707\n",
      "Current loss value: 9577.551\n",
      "Current loss value: 10191.199\n",
      "Current loss value: 10790.878\n",
      "Current loss value: 11376.125\n",
      "Current loss value: 11947.558\n",
      "Current loss value: 12515.035\n",
      "Current loss value: 13078.709\n",
      "Current loss value: 13636.814\n",
      "Current loss value: 14196.913\n",
      "Current loss value: 14753.111\n",
      "Current loss value: 15299.971\n",
      "Current loss value: 15841.708\n",
      "Current loss value: 16382.354\n",
      "Current loss value: 16919.164\n",
      "Current loss value: 17449.77\n",
      "Filter 114 processed in 1s\n",
      "Processing filter 115\n",
      "Current loss value: 744.2411\n",
      "Current loss value: 860.8271\n",
      "Current loss value: 965.9625\n",
      "Current loss value: 1043.1235\n",
      "Current loss value: 1117.7557\n",
      "Current loss value: 1192.2585\n",
      "Current loss value: 1263.6985\n",
      "Current loss value: 1330.9968\n",
      "Current loss value: 1394.1257\n",
      "Current loss value: 1457.2858\n",
      "Current loss value: 1520.678\n",
      "Current loss value: 1583.9768\n",
      "Current loss value: 1649.3757\n",
      "Current loss value: 1717.5978\n",
      "Current loss value: 1785.7373\n",
      "Current loss value: 1852.6145\n",
      "Current loss value: 1918.6108\n",
      "Current loss value: 1983.6274\n",
      "Current loss value: 2050.5369\n",
      "Current loss value: 2123.3364\n",
      "Filter 115 processed in 1s\n",
      "Processing filter 116\n",
      "Current loss value: 8151.4507\n",
      "Current loss value: 8406.341\n",
      "Current loss value: 8690.744\n",
      "Current loss value: 8982.578\n",
      "Current loss value: 9297.886\n",
      "Current loss value: 9623.52\n",
      "Current loss value: 9950.754\n",
      "Current loss value: 10276.457\n",
      "Current loss value: 10596.905\n",
      "Current loss value: 10913.199\n",
      "Current loss value: 11227.23\n",
      "Current loss value: 11544.186\n",
      "Current loss value: 11863.551\n",
      "Current loss value: 12182.451\n",
      "Current loss value: 12503.393\n",
      "Current loss value: 12824.229\n",
      "Current loss value: 13146.729\n",
      "Current loss value: 13469.494\n",
      "Current loss value: 13793.899\n",
      "Current loss value: 14119.939\n",
      "Filter 116 processed in 1s\n",
      "Processing filter 117\n",
      "Current loss value: 15387.709\n",
      "Current loss value: 16155.271\n",
      "Current loss value: 16944.059\n",
      "Current loss value: 17730.645\n",
      "Current loss value: 18550.113\n",
      "Current loss value: 19365.434\n",
      "Current loss value: 20174.572\n",
      "Current loss value: 20969.871\n",
      "Current loss value: 21751.264\n",
      "Current loss value: 22529.469\n",
      "Current loss value: 23296.295\n",
      "Current loss value: 24063.398\n",
      "Current loss value: 24828.955\n",
      "Current loss value: 25594.031\n",
      "Current loss value: 26353.271\n",
      "Current loss value: 27108.521\n",
      "Current loss value: 27855.059\n",
      "Current loss value: 28598.137\n",
      "Current loss value: 29339.281\n",
      "Current loss value: 30080.486\n",
      "Filter 117 processed in 1s\n",
      "Processing filter 118\n",
      "Current loss value: 8218.096\n",
      "Current loss value: 8947.865\n",
      "Current loss value: 9674.487\n",
      "Current loss value: 10403.3\n",
      "Current loss value: 11133.49\n",
      "Current loss value: 11857.282\n",
      "Current loss value: 12572.075\n",
      "Current loss value: 13270.947\n",
      "Current loss value: 13960.097\n",
      "Current loss value: 14643.488\n",
      "Current loss value: 15318.983\n",
      "Current loss value: 15993.752\n",
      "Current loss value: 16665.152\n",
      "Current loss value: 17336.947\n",
      "Current loss value: 18005.543\n",
      "Current loss value: 18673.98\n",
      "Current loss value: 19338.912\n",
      "Current loss value: 20002.938\n",
      "Current loss value: 20666.117\n",
      "Current loss value: 21328.074\n",
      "Filter 118 processed in 1s\n",
      "Processing filter 119\n",
      "Current loss value: 10554.691\n",
      "Current loss value: 11041.129\n",
      "Current loss value: 11550.479\n",
      "Current loss value: 12069.211\n",
      "Current loss value: 12616.045\n",
      "Current loss value: 13167.269\n",
      "Current loss value: 13711.984\n",
      "Current loss value: 14253.759\n",
      "Current loss value: 14782.602\n",
      "Current loss value: 15305.027\n",
      "Current loss value: 15825.8125\n",
      "Current loss value: 16344.031\n",
      "Current loss value: 16863.535\n",
      "Current loss value: 17378.312\n",
      "Current loss value: 17893.729\n",
      "Current loss value: 18410.863\n",
      "Current loss value: 18926.992\n",
      "Current loss value: 19445.615\n",
      "Current loss value: 19959.543\n",
      "Current loss value: 20473.203\n",
      "Filter 119 processed in 1s\n",
      "Processing filter 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 20091.79\n",
      "Current loss value: 21466.684\n",
      "Current loss value: 22878.428\n",
      "Current loss value: 24339.277\n",
      "Current loss value: 25855.523\n",
      "Current loss value: 27378.43\n",
      "Current loss value: 28897.46\n",
      "Current loss value: 30419.219\n",
      "Current loss value: 31941.246\n",
      "Current loss value: 33459.496\n",
      "Current loss value: 34973.43\n",
      "Current loss value: 36479.91\n",
      "Current loss value: 37993.875\n",
      "Current loss value: 39498.184\n",
      "Current loss value: 40992.625\n",
      "Current loss value: 42487.938\n",
      "Current loss value: 43985.867\n",
      "Current loss value: 45480.184\n",
      "Current loss value: 46978.383\n",
      "Current loss value: 48474.74\n",
      "Filter 120 processed in 1s\n",
      "Processing filter 121\n",
      "Current loss value: 6882.837\n",
      "Current loss value: 7472.1953\n",
      "Current loss value: 8057.625\n",
      "Current loss value: 8639.739\n",
      "Current loss value: 9233.189\n",
      "Current loss value: 9833.072\n",
      "Current loss value: 10426.822\n",
      "Current loss value: 11007.599\n",
      "Current loss value: 11576.15\n",
      "Current loss value: 12135.51\n",
      "Current loss value: 12693.096\n",
      "Current loss value: 13247.582\n",
      "Current loss value: 13800.459\n",
      "Current loss value: 14351.127\n",
      "Current loss value: 14903.047\n",
      "Current loss value: 15450.678\n",
      "Current loss value: 15996.741\n",
      "Current loss value: 16542.549\n",
      "Current loss value: 17088.424\n",
      "Current loss value: 17637.6\n",
      "Filter 121 processed in 1s\n",
      "Processing filter 122\n",
      "Current loss value: 5596.6953\n",
      "Current loss value: 5831.5103\n",
      "Current loss value: 6073.466\n",
      "Current loss value: 6300.7236\n",
      "Current loss value: 6532.841\n",
      "Current loss value: 6769.9155\n",
      "Current loss value: 7005.9814\n",
      "Current loss value: 7243.225\n",
      "Current loss value: 7473.5845\n",
      "Current loss value: 7696.8975\n",
      "Current loss value: 7917.7705\n",
      "Current loss value: 8137.927\n",
      "Current loss value: 8357.881\n",
      "Current loss value: 8572.221\n",
      "Current loss value: 8784.152\n",
      "Current loss value: 8995.488\n",
      "Current loss value: 9204.678\n",
      "Current loss value: 9408.841\n",
      "Current loss value: 9616.662\n",
      "Current loss value: 9821.273\n",
      "Filter 122 processed in 1s\n",
      "Processing filter 123\n",
      "Current loss value: 3199.463\n",
      "Current loss value: 3413.2847\n",
      "Current loss value: 3629.982\n",
      "Current loss value: 3844.4358\n",
      "Current loss value: 4066.287\n",
      "Current loss value: 4294.073\n",
      "Current loss value: 4522.048\n",
      "Current loss value: 4740.024\n",
      "Current loss value: 4951.876\n",
      "Current loss value: 5159.632\n",
      "Current loss value: 5363.573\n",
      "Current loss value: 5563.6367\n",
      "Current loss value: 5761.4634\n",
      "Current loss value: 5955.6064\n",
      "Current loss value: 6148.8555\n",
      "Current loss value: 6340.1016\n",
      "Current loss value: 6529.8154\n",
      "Current loss value: 6719.4253\n",
      "Current loss value: 6907.2705\n",
      "Current loss value: 7093.738\n",
      "Filter 123 processed in 1s\n",
      "Processing filter 124\n",
      "Current loss value: 15.673039\n",
      "Current loss value: 22.49578\n",
      "Current loss value: 29.25391\n",
      "Current loss value: 40.34565\n",
      "Current loss value: 55.466984\n",
      "Current loss value: 75.385895\n",
      "Current loss value: 95.53568\n",
      "Current loss value: 119.26733\n",
      "Current loss value: 151.63922\n",
      "Current loss value: 196.51355\n",
      "Current loss value: 245.95493\n",
      "Current loss value: 295.7626\n",
      "Current loss value: 345.81485\n",
      "Current loss value: 401.72925\n",
      "Current loss value: 461.17172\n",
      "Current loss value: 523.13477\n",
      "Current loss value: 589.52466\n",
      "Current loss value: 661.0419\n",
      "Current loss value: 744.48047\n",
      "Current loss value: 834.2401\n",
      "Filter 124 processed in 1s\n",
      "Processing filter 125\n",
      "Current loss value: 303.86615\n",
      "Current loss value: 356.15906\n",
      "Current loss value: 455.75772\n",
      "Current loss value: 592.46655\n",
      "Current loss value: 791.7418\n",
      "Current loss value: 1058.4827\n",
      "Current loss value: 1371.3235\n",
      "Current loss value: 1697.1234\n",
      "Current loss value: 2033.5017\n",
      "Current loss value: 2388.3777\n",
      "Current loss value: 2752.1238\n",
      "Current loss value: 3125.7148\n",
      "Current loss value: 3503.9302\n",
      "Current loss value: 3889.5906\n",
      "Current loss value: 4276.1055\n",
      "Current loss value: 4665.0415\n",
      "Current loss value: 5058.29\n",
      "Current loss value: 5456.544\n",
      "Current loss value: 5859.2373\n",
      "Current loss value: 6274.3413\n",
      "Filter 125 processed in 1s\n",
      "Processing filter 126\n",
      "Current loss value: 0.0\n",
      "Filter 126 processed in 1s\n",
      "Processing filter 127\n",
      "Current loss value: 8069.04\n",
      "Current loss value: 8467.579\n",
      "Current loss value: 8879.952\n",
      "Current loss value: 9298.097\n",
      "Current loss value: 9732.074\n",
      "Current loss value: 10162.983\n",
      "Current loss value: 10588.443\n",
      "Current loss value: 11008.522\n",
      "Current loss value: 11422.84\n",
      "Current loss value: 11830.699\n",
      "Current loss value: 12239.133\n",
      "Current loss value: 12641.434\n",
      "Current loss value: 13039.395\n",
      "Current loss value: 13435.677\n",
      "Current loss value: 13827.209\n",
      "Current loss value: 14217.925\n",
      "Current loss value: 14607.595\n",
      "Current loss value: 14997.642\n",
      "Current loss value: 15383.673\n",
      "Current loss value: 15767.223\n",
      "Filter 127 processed in 1s\n"
     ]
    }
   ],
   "source": [
    "kept_filters = []\n",
    "for filter_index in range(128):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 8\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        width_margin = (img_width + margin) * i\n",
    "        height_margin = (img_height + margin) * j\n",
    "        stitched_filters[\n",
    "            width_margin: width_margin + img_width,\n",
    "            height_margin: height_margin + img_height, :] = img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result to disk\n",
    "save_img('stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_valid).ravel()\n",
    "prediction_probabilities = model.predict(X_valid).ravel()\n",
    "all_vehicles = np.array(emergency_vehicles + nonemergency_vehicles)\n",
    "\n",
    "_, valid_vehicles, _, valid_y = train_test_split(all_vehicles,train_y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions = valid_vehicles[predictions == Y_valid]\n",
    "\n",
    "index = rng.choice(range(len(correct_predictions)))\n",
    "img_name = correct_predictions[index]\n",
    "\n",
    "\n",
    "prob = (prediction_probabilities[predictions == Y_valid] * 100).astype(int)[index]\n",
    "\n",
    "img = imread('../datasets/emergency_classification/images/' + img_name)\n",
    "\n",
    "print(prob , '% sure that it is emergency')\n",
    "pylab.imshow(img)\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_predictions = valid_vehicles[predictions != Y_valid]\n",
    "index = rng.choice(range(len(incorrect_predictions)))\n",
    "img_name = incorrect_predictions[index]\n",
    "\n",
    "\n",
    "prob = (prediction_probabilities[predictions != Y_valid] * 100).astype(int)[index]\n",
    "\n",
    "img = imread('../datasets/emergency_classification/images/' + img_name)\n",
    "\n",
    "print(prob , '% sure that it is emergency')\n",
    "pylab.imshow(img)\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(predictions, Y_valid).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, tp, fn, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(predictions, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_layer = model.layers[0]\n",
    "plt.imshow(top_layer.get_weights()[0][:, :, :, 0].squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = np.abs(top_layer.get_weights()[0][:, :, :, 0].squeeze().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(top_layer.get_weights()[0][:, :, :, 0].squeeze() + min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_activation\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "layer_idx = -1\n",
    "\n",
    "# Swap softmax with linear\n",
    "model.layers[layer_idx].activation = activations.linear\n",
    "\n",
    "# This is the output node we want to maximize.\n",
    "filter_idx = 0\n",
    "img = visualize_activation(model, layer_idx, filter_indices=filter_idx)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from vis.visualization import get_num_filters\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# You can see this in the model definition.\n",
    "layer_idx = 4\n",
    "\n",
    "# Visualize all filters in this layer.\n",
    "filters = np.arange(get_num_filters(model.layers[layer_idx]))\n",
    "\n",
    "# Generate input image for each filter.\n",
    "vis_images = []\n",
    "for idx in filters[:4]:\n",
    "    img = visualize_activation(model, layer_idx, filter_indices=idx)\n",
    "    \n",
    "    # Utility to overlay text on image.\n",
    "    img = utils.draw_text(img, 'Filter {}'.format(idx))    \n",
    "    vis_images.append(img)\n",
    "\n",
    "# Generate stitched image palette with 8 cols.\n",
    "stitched = utils.stitch_images(vis_images, cols=8)    \n",
    "plt.axis('off')\n",
    "plt.imshow(stitched)\n",
    "plt.title(layer_idx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = rng.choice(emergency_vehicles)\n",
    "\n",
    "img = imread('../datasets/emergency_classification/images/' +img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from vis.visualization import visualize_cam\n",
    "from vis.visualization import visualize_saliency, overlay\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "f, ax = plt.subplots()\n",
    "plt.suptitle(\"vanilla\")\n",
    "\n",
    "grads = visualize_cam(model, -1, filter_indices=0, \n",
    "                      seed_input=img, backprop_modifier=None)        \n",
    "# Lets overlay the heatmap onto original image.    \n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "ax.imshow(overlay(jet_heatmap, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in emergency_vehicles:\n",
    "    img = imread('../datasets/emergency_classification/images/' + img_name)\n",
    "    \n",
    "    plt.figure()\n",
    "    f, ax = plt.subplots()\n",
    "    plt.suptitle(\"vanilla\")\n",
    "\n",
    "    grads = visualize_cam(model, -1, filter_indices=0, \n",
    "                          seed_input=img, backprop_modifier=None)        \n",
    "    # Lets overlay the heatmap onto original image.    \n",
    "    jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "    ax.imshow(overlay(jet_heatmap, img))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = glob('../datasets/emergency_classification/images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = vehicles[285]\n",
    "img = imread(img_name)\n",
    "\n",
    "plt.figure()\n",
    "f, ax = plt.subplots()\n",
    "plt.suptitle(\"vanilla\")\n",
    "\n",
    "grads = visualize_cam(model, -1, filter_indices=0, \n",
    "                      seed_input=img, backprop_modifier=None)        \n",
    "# Lets overlay the heatmap onto original image.    \n",
    "jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n",
    "ax.imshow(overlay(jet_heatmap, img))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
